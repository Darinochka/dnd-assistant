{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxONqFfTgr4_",
        "outputId": "2f92a9d1-3975-4b99-9628-bab5a03c656a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install -q nest_asyncio\n",
        "!pip install -q -U python-telegram-bot\n",
        "!pip install -q sentence-transformers pypdf requests pdfminer.six psutil pymupdf\n",
        "!pip install -q langchain-community langchain-text-splitters faiss-cpu\n",
        "!pip install -q hf_xet omegaconf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9N6p2KwNgNAe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TG_BOT_TOKEN\"] = \"\"\n",
        "os.environ[\"OLLAMA_API_KEY\"] = \"\"  \n",
        "os.environ[\"OLLAMA_API_URL\"] = \"https://ollama.com/api/chat\"\n",
        "os.environ[\"OLLAMA_MODEL\"] = \"gpt-oss:20b-cloud\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PROMPTS / STYLE (Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑŽÑ‚ÑÑ Ð±Ð¾Ñ‚Ð¾Ð¼ Ð½Ð¸Ð¶Ðµ)\n",
        "\n",
        "TELEGRAM_STYLE_SYSTEM = (\n",
        "    \"ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð´Ð»Ñ Ñ‡Ð°Ñ‚Ð° Telegram. Ð’Ñ‹Ð²Ð¾Ð´ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ñ€Ð¾ÑÑ‚Ñ‹Ð¼ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼. \"\n",
        "    \"Ð—Ð°Ð¿Ñ€ÐµÑ‰ÐµÐ½Ð¾: ÑÑ…ÐµÐ¼Ñ‹/ASCII-Ð°Ñ€Ñ‚, Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹, ÑÐ¿Ð¸ÑÐºÐ¸ Ñ Ð¼Ð°Ñ€ÐºÐµÑ€Ð°Ð¼Ð¸, Markdown (**, #, ```), JSON/XML/YAML, ÐºÐ¾Ð´. \"\n",
        "    \"ÐŸÐ¸ÑˆÐ¸ ÐºÑ€Ð°Ñ‚ÐºÐ¾ Ð¸ Ð¿Ð¾ Ð´ÐµÐ»Ñƒ: 6â€“10 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹, Ð±ÐµÐ· Ð»Ð¸ÑˆÐ½ÐµÐ¹ Ð²Ð¾Ð´Ñ‹. \"\n",
        "    \"Ð•ÑÐ»Ð¸ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ â€” Ð¿Ñ€ÑÐ¼Ð¾ ÑÐºÐ°Ð¶Ð¸, Ñ‡ÐµÐ³Ð¾ Ð½ÐµÑ‚ Ð² ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ðµ, Ð¸ Ñ‡Ñ‚Ð¾ Ð½ÑƒÐ¶Ð½Ð¾ ÑƒÑ‚Ð¾Ñ‡Ð½Ð¸Ñ‚ÑŒ.\"\n",
        ")\n",
        "\n",
        "PC_SHEET_PROMPT = \"\"\"Ð¢Ñ‹ â€” Ð¼Ð°ÑÑ‚ÐµÑ€ Ð¿Ð¾ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸ÑŽ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð¶ÐµÐ¹ Dungeons & Dragons 5e. ÐÐ° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… ÑÑ„Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐ¹ Ð¿Ð¾Ð»Ð½Ð¾Ðµ, Ð¶Ð¸Ð²Ð¾Ðµ Ð¸ ÑƒÐ´Ð¾Ð±Ð¾Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð¶Ð°, Ð¾Ñ€Ð¸ÐµÐ½Ñ‚Ð¸Ñ€ÑƒÑÑÑŒ Ð½Ð° Ð¾Ñ„Ð¸Ñ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð»Ð¸ÑÑ‚ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð¶Ð° (character sheet).\n",
        "\n",
        "Ð’Ñ‹Ð²Ð¾Ð´ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð² Ð²Ð¸Ð´Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°, Ð±ÐµÐ· Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ, Ñ‚Ð°Ð±Ð»Ð¸Ñ†, ÑÐ¿Ð¸ÑÐºÐ¾Ð² Ð¸Ð»Ð¸ Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… ÐºÐ¾Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¹. ÐšÐ°Ð¶Ð´Ð°Ñ ÑÐµÐºÑ†Ð¸Ñ Ð½Ð°Ñ‡Ð¸Ð½Ð°ÐµÑ‚ÑÑ Ñ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ°, Ð·Ð° ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¼ ÑÐ»ÐµÐ´ÑƒÐµÑ‚ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸Ðµ. Ð¡Ð¾Ð±Ð»ÑŽÐ´Ð°Ð¹ ÑÑ‚Ñ€Ð¾Ð³Ð¾ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¹ Ð¿Ð¾Ñ€ÑÐ´Ð¾Ðº:\n",
        "\n",
        "Ð˜Ð¼Ñ: [Ð¿Ð¾Ð»Ð½Ð¾Ðµ Ð¸Ð¼Ñ]\n",
        "Ð Ð°ÑÐ°: [Ñ€Ð°ÑÐ° Ð¸ Ð¿Ð¾Ð´Ñ€Ð°ÑÐ°, ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ]\n",
        "ÐšÐ»Ð°ÑÑ: [ÐºÐ»Ð°ÑÑ, Ð°Ñ€Ñ…ÐµÑ‚Ð¸Ð¿/Ð¿Ð¾Ð´ÐºÐ»Ð°ÑÑ, ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ]\n",
        "ÐŸÑ€ÐµÐ´Ñ‹ÑÑ‚Ð¾Ñ€Ð¸Ñ: [Ð¿Ñ€Ð¾Ð¸ÑÑ…Ð¾Ð¶Ð´ÐµÐ½Ð¸Ðµ, Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: Â«Ð½Ð°Ñ‘Ð¼Ð½Ð¸ÐºÂ», Â«ÑƒÑ‡Ñ‘Ð½Ñ‹Ð¹Â», Â«Ð¸Ð·Ð³Ð½Ð°Ð½Ð½Ð¸ÐºÂ»]\n",
        "ÐœÐ¸Ñ€Ð¾Ð²Ð¾Ð·Ð·Ñ€ÐµÐ½Ð¸Ðµ: [Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: Â«Ð½ÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ð¾-Ð´Ð¾Ð±Ñ€Ñ‹Ð¹Â»]\n",
        "\n",
        "Ð¥Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸ÐºÐ¸:\n",
        "Ð¡Ð¸Ð»Ð° [Ñ‡Ð¸ÑÐ»Ð¾] (+Ð¼Ð¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€)\n",
        "Ð›Ð¾Ð²ÐºÐ¾ÑÑ‚ÑŒ [Ñ‡Ð¸ÑÐ»Ð¾] (+Ð¼Ð¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€)\n",
        "Ð¢ÐµÐ»Ð¾ÑÐ»Ð¾Ð¶ÐµÐ½Ð¸Ðµ [Ñ‡Ð¸ÑÐ»Ð¾] (+Ð¼Ð¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€)\n",
        "Ð˜Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ [Ñ‡Ð¸ÑÐ»Ð¾] (+Ð¼Ð¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€)\n",
        "ÐœÑƒÐ´Ñ€Ð¾ÑÑ‚ÑŒ [Ñ‡Ð¸ÑÐ»Ð¾] (+Ð¼Ð¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€)\n",
        "Ð¥Ð°Ñ€Ð¸Ð·Ð¼Ð° [Ñ‡Ð¸ÑÐ»Ð¾] (+Ð¼Ð¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€)\n",
        "\n",
        "ÐšÐ»Ð°ÑÑÐ¾Ð²Ñ‹Ðµ ÑÐ¿Ð°ÑÐ±Ñ€Ð¾ÑÐºÐ¸: [Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: Â«Ð¡Ð¸Ð»Ð° +5, Ð¢ÐµÐ»Ð¾ÑÐ»Ð¾Ð¶ÐµÐ½Ð¸Ðµ +4Â»]\n",
        "Ð‘Ñ€Ð¾Ð½Ñ: [ÐºÐ»Ð°ÑÑ Ð±Ñ€Ð¾Ð½Ð¸, Ñ‚Ð¸Ð¿ Ð±Ñ€Ð¾Ð½Ð¸]\n",
        "Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ñ‚Ð¸Ð²Ð°: [+Ð¼Ð¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€]\n",
        "Ð¡ÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ: [Ð² Ñ„ÑƒÑ‚Ð°Ñ…, Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: Â«30 Ñ„Ñ‚Â»]\n",
        "ÐœÐ°ÐºÑÐ¸Ð¼ÑƒÐ¼ Ñ…Ð¸Ñ‚Ð¾Ð²: [Ñ‡Ð¸ÑÐ»Ð¾]\n",
        "Ð¢ÐµÐºÑƒÑ‰Ð¸Ðµ Ñ…Ð¸Ñ‚Ñ‹: [Ñ‡Ð¸ÑÐ»Ð¾]\n",
        "Ð’Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ñ…Ð¸Ñ‚Ñ‹: [Ñ‡Ð¸ÑÐ»Ð¾ Ð¸Ð»Ð¸ Â«Ð½ÐµÑ‚Â»]\n",
        "\n",
        "ÐÐ°Ð²Ñ‹ÐºÐ¸: [Ð¿ÐµÑ€ÐµÑ‡Ð¸ÑÐ»Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ‚Ðµ, Ð² ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ñ… Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð¶ ÐºÐ¾Ð¼Ð¿ÐµÑ‚ÐµÐ½Ñ‚ÐµÐ½, Ñ Ð±Ð¾Ð½ÑƒÑÐ°Ð¼Ð¸, Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: Â«Ð’Ð½Ð¸Ð¼Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ +6, Ð—Ð°Ð¿ÑƒÐ³Ð¸Ð²Ð°Ð½Ð¸Ðµ +5, ÐÐºÑ€Ð¾Ð±Ð°Ñ‚Ð¸ÐºÐ° +4Â»]\n",
        "\n",
        "Ð¯Ð·Ñ‹ÐºÐ¸ Ð¸ Ð²Ð»Ð°Ð´ÐµÐ½Ð¸Ñ: [ÑÐ·Ñ‹ÐºÐ¸, Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ñ‹, Ð¾Ñ€ÑƒÐ¶Ð¸Ðµ, Ð±Ñ€Ð¾Ð½Ñ â€” ÐºÑ€Ð°Ñ‚ÐºÐ¾ Ñ‡ÐµÑ€ÐµÐ· Ð·Ð°Ð¿ÑÑ‚ÑƒÑŽ]\n",
        "\n",
        "Ð§ÐµÑ€Ñ‚Ñ‹ Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð°: [1â€“2 ÑÑ€ÐºÐ¸Ðµ Ð¾ÑÐ¾Ð±ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ð¾Ð²ÐµÐ´ÐµÐ½Ð¸Ñ]\n",
        "Ð˜Ð´ÐµÐ°Ð»Ñ‹: [Ð²Ð¾ Ñ‡Ñ‚Ð¾ Ð²ÐµÑ€Ð¸Ñ‚]\n",
        "ÐŸÑ€Ð¸Ð²ÑÐ·Ð°Ð½Ð½Ð¾ÑÑ‚Ð¸: [ÐºÑ‚Ð¾ Ð¸Ð»Ð¸ Ñ‡Ñ‚Ð¾ ÐµÐ¼Ñƒ Ð´Ð¾Ñ€Ð¾Ð³Ð¾]\n",
        "Ð¡Ð»Ð°Ð±Ð¾ÑÑ‚Ð¸: [ÑÑ‚Ñ€Ð°Ñ…Ð¸, Ð¿Ð¾Ñ€Ð¾ÐºÐ¸, Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ðµ ÐºÐ¾Ð½Ñ„Ð»Ð¸ÐºÑ‚Ñ‹]\n",
        "\n",
        "Ð’Ð½ÐµÑˆÐ½Ð¾ÑÑ‚ÑŒ: [Ñ€Ð¾ÑÑ‚, Ð²ÐµÑ, Ñ†Ð²ÐµÑ‚ Ð³Ð»Ð°Ð·/Ð²Ð¾Ð»Ð¾Ñ/ÐºÐ¾Ð¶Ð¸, Ð¾Ð´ÐµÐ¶Ð´Ð°, ÑˆÑ€Ð°Ð¼Ñ‹, ÑƒÐºÑ€Ð°ÑˆÐµÐ½Ð¸Ñ â€” Ð²ÑÑ‘, Ñ‡Ñ‚Ð¾ Ð²Ð¸Ð´Ð½Ð¾ ÑÑ€Ð°Ð·Ñƒ]\n",
        "\n",
        "Ð¡Ð¾ÑŽÐ·Ð½Ð¸ÐºÐ¸ Ð¸ Ð¾Ñ€Ð³Ð°Ð½Ð¸Ð·Ð°Ñ†Ð¸Ð¸: [ÐºÑ‚Ð¾ Ð½Ð° ÐµÐ³Ð¾ ÑÑ‚Ð¾Ñ€Ð¾Ð½Ðµ, Ñ‡Ð»ÐµÐ½ÑÑ‚Ð²Ð¾ Ð² Ð³Ñ€ÑƒÐ¿Ð¿Ð°Ñ…]\n",
        "\n",
        "Ð¦ÐµÐ»ÑŒ: [Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ Ð¾Ð½ Ð¿ÑƒÑ‚ÐµÑˆÐµÑÑ‚Ð²ÑƒÐµÑ‚, Ñ‡Ñ‚Ð¾ Ð¸Ñ‰ÐµÑ‚ Ð¸Ð»Ð¸ Ð·Ð°Ñ‰Ð¸Ñ‰Ð°ÐµÑ‚]\n",
        "\n",
        "ÐžÑÐ¾Ð±Ñ‹Ðµ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚Ð¸ Ð¸ Ñ‡ÐµÑ€Ñ‚Ñ‹ Ñ€Ð°ÑÑ‹/ÐºÐ»Ð°ÑÑÐ°: [ÐºÑ€Ð°Ñ‚ÐºÐ¾ â€” Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ‚Ð¾, Ñ‡Ñ‚Ð¾ Ð²Ð°Ð¶Ð½Ð¾ Ð´Ð»Ñ Ð¸Ð³Ñ€Ñ‹ Ð¸ Ð¾Ñ‚Ñ‹Ð³Ñ€Ñ‹ÑˆÐ°, Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: Â«Ð¢ÐµÐ¼Ð½Ð¾Ðµ Ð·Ñ€ÐµÐ½Ð¸Ðµ 60 Ñ„Ñ‚Â», Â«Ð‘Ð¾ÐµÐ²Ð¾Ð¹ ÑÑ‚Ð¸Ð»ÑŒ: Ð—Ð°Ñ‰Ð¸Ñ‚Ð°Â», Â«Ð£Ð´Ð°Ñ‡Ð° Ð¿Ð¾Ð»ÑƒÑ€Ð¾ÑÐ»Ð¸ÐºÐ°Â»]\n",
        "\n",
        "ÐÐµ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐ¹ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ð¹, ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ² Ð¸Ð»Ð¸ Ð»Ð¸ÑˆÐ½Ð¸Ñ… ÑÐ»Ð¾Ð². ÐÐµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¶Ð¸Ñ€Ð½Ñ‹Ð¹ ÑˆÑ€Ð¸Ñ„Ñ‚, ÐºÑƒÑ€ÑÐ¸Ð², Ð·Ð²Ñ‘Ð·Ð´Ð¾Ñ‡ÐºÐ¸, Ñ‚Ð¸Ñ€Ðµ ÐºÐ°Ðº Ð¼Ð°Ñ€ÐºÐµÑ€Ñ‹, JSON, XML Ð¸Ð»Ð¸ Ð»ÑŽÐ±Ñ‹Ðµ Ð´Ñ€ÑƒÐ³Ð¸Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ‹. Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ñ‡Ð¸ÑÑ‚Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ â€” ÐºÐ°Ð¶Ð´Ð°Ñ ÑÑ‚Ñ€Ð¾ÐºÐ° Ð½Ð°Ñ‡Ð¸Ð½Ð°ÐµÑ‚ÑÑ Ñ ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ°.\"\"\"\n",
        "\n",
        "NPC_PROMPT = \"\"\"Ð¡Ð¾Ð·Ð´Ð°Ð¹ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð½ÐµÐ¸Ð³Ñ€Ð¾Ð²Ð¾Ð³Ð¾ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð¶Ð° (NPC) Ð´Ð»Ñ Dungeons & Dragons 5e. Ð’Ñ‹Ð²ÐµÐ´Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð¹ Ñ‚ÐµÐºÑÑ‚, Ð±ÐµÐ· Ñ‚Ð°Ð±Ð»Ð¸Ñ†, ÑÐ¿Ð¸ÑÐºÐ¾Ð² Ð¸Ð»Ð¸ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ. Ð¡Ð¾Ð±Ð»ÑŽÐ´Ð°Ð¹ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÑƒÑŽ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ â€” ÐºÐ°Ð¶Ð´Ð°Ñ ÑÑ‚Ñ€Ð¾ÐºÐ° Ð½Ð°Ñ‡Ð¸Ð½Ð°ÐµÑ‚ÑÑ Ñ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ°:\n",
        "\n",
        "Ð˜Ð¼Ñ:\n",
        "Ð Ð°ÑÐ°:\n",
        "Ð’Ð¾Ð·Ñ€Ð°ÑÑ‚:\n",
        "Ð Ð¾Ð´ Ð·Ð°Ð½ÑÑ‚Ð¸Ð¹:\n",
        "ÐœÐ¸Ñ€Ð¾Ð²Ð¾Ð·Ð·Ñ€ÐµÐ½Ð¸Ðµ:\n",
        "Ð’Ð½ÐµÑˆÐ½Ð¾ÑÑ‚ÑŒ:\n",
        "Ð¥Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€:\n",
        "Ð¦ÐµÐ»ÑŒ Ð¸Ð»Ð¸ Ð¼Ð¾Ñ‚Ð¸Ð²Ð°Ñ†Ð¸Ñ:\n",
        "ÐžÑ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ðµ Ðº Ð¸Ð³Ñ€Ð¾ÐºÐ°Ð¼:\n",
        "ÐžÑÐ¾Ð±ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸:\n",
        "Ð¡ÐµÐºÑ€ÐµÑ‚:\n",
        "\n",
        "ÐŸÐ¸ÑˆÐ¸ ÐºÑ€Ð°Ñ‚ÐºÐ¾ Ð¸ ÐµÑÑ‚ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾. ÐžÑÐ¾Ð±ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸ â€” ÑÑ‚Ð¾ Ñ‚Ð¾, Ñ‡Ñ‚Ð¾ Ð´ÐµÐ»Ð°ÐµÑ‚ NPC Ð·Ð°Ð¿Ð¾Ð¼Ð¸Ð½Ð°ÑŽÑ‰Ð¸Ð¼ÑÑ (Ð¿Ñ€Ð¸Ð²Ñ‹Ñ‡ÐºÐ°, Ð¼Ð°Ð½ÐµÑ€Ð° Ñ€ÐµÑ‡Ð¸, Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚ Ð¾Ð´ÐµÐ¶Ð´Ñ‹ Ð¸ Ñ‚.Ð¿.). Ð¡ÐµÐºÑ€ÐµÑ‚ â€” Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð½ÐµÐ·Ð½Ð°Ñ‡Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼ (Â«Ð±Ð¾Ð¸Ñ‚ÑÑ ÐºÑ€Ñ‹ÑÂ») Ð¸Ð»Ð¸ Ð²Ð°Ð¶Ð½Ñ‹Ð¼ (Â«ÐºÐ¾Ð½Ñ‚Ñ€Ð°Ð±Ð°Ð½Ð´Ð¸ÑÑ‚Â»), Ð½Ð¾ ÐµÑÐ»Ð¸ NPC Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð¾Ð±Ñ‹Ð´ÐµÐ½Ð½Ñ‹Ð¹ â€” ÑÐµÐºÑ€ÐµÑ‚ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¿ÑƒÑÑ‚Ñ‹Ð¼ Ð¸Ð»Ð¸ Ð±Ñ‹Ñ‚Ð¾Ð²Ñ‹Ð¼. ÐÐµ Ð²Ñ‹Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ð¹ ÑÐ¿Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð´ÐµÑ‚Ð°Ð»Ð¸, ÐµÑÐ»Ð¸ Ð¾Ð½Ð¸ Ð½Ðµ ÑƒÐ¼ÐµÑÑ‚Ð½Ñ‹. Ð“Ð»Ð°Ð²Ð½Ð¾Ðµ â€” Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð±Ñ‹Ð»Ð¾ Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð´Ð»Ñ Ð¶Ð¸Ð²Ð¾Ð³Ð¾ Ð¾Ñ‚Ñ‹Ð³Ñ€Ñ‹ÑˆÐ° Ð·Ð° 1â€“2 Ð¼Ð¸Ð½ÑƒÑ‚Ñ‹.\"\"\"\n",
        "\n",
        "NPC_DIALOG_PROMPT = \"\"\"Ð¢Ñ‹ â€” NPC Ð² Ñ„ÑÐ½Ñ‚ÐµÐ·Ð¸Ð¹Ð½Ð¾Ð¹ ÐºÐ°Ð¼Ð¿Ð°Ð½Ð¸Ð¸ Dungeons & Dragons 5e.\n",
        "\n",
        "Ð¢ÐµÐ±Ðµ Ð±ÑƒÐ´ÐµÑ‚ Ð´Ð°Ð½Ð¾:\n",
        "1) ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ ÑÐµÑ‚Ñ‚Ð¸Ð½Ð³Ð°/ÐºÐ°Ð¼Ð¿Ð°Ð½Ð¸Ð¸ (ÐµÑÐ»Ð¸ Ð½Ð°Ð¹Ð´ÐµÐ½), ÐµÑÐ»Ð¸ Ð½ÐµÑ‚ ÐµÐ³Ð¾, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¤Ð°ÑÑ€ÑƒÐ½ ÐºÐ°Ðº Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ ÑÐµÑ‚Ñ‚Ð¸Ð½Ð³\n",
        "2) Ð ÐµÐ¿Ð»Ð¸ÐºÐ°/ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ð¸Ñ, Ð½Ð° ÐºÐ¾Ñ‚Ð¾Ñ€ÑƒÑŽ Ð½ÑƒÐ¶Ð½Ð¾ ÑÐ¸Ð¼Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ, Ñ‡Ð°Ñ‰Ðµ Ð²ÑÐµÐ³Ð¾ ÑÑ‚Ð¾ Ñ€ÐµÐ¿Ð»Ð¸ÐºÐ° Ð¾Ð±Ñ€Ð°Ñ‰ÐµÐ½Ð°Ñ Ðº Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð¶Ð°Ð¼ Ð¸Ð³Ñ€Ð¾ÐºÐ¾Ð²\n",
        "\n",
        "Ð¢Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ Ðº ÑÑ‚Ð¸Ð»ÑŽ Ð¸ ÑÐµÑ‚Ñ‚Ð¸Ð½Ð³Ñƒ:\n",
        "ÐÐµ Ð±ÑƒÐ´ÑŒ Ð¸Ð·Ð»Ð¸ÑˆÐ½Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¼, Ð²ÐµÐ´Ð¸ ÑÐµÐ±Ñ ÐµÑÑ‚ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾\n",
        "ÐŸÐ¸ÑˆÐ¸ Ð¿Ð¾-Ñ€ÑƒÑÑÐºÐ¸, Ð³Ñ€Ð°Ð¼Ð¾Ñ‚Ð½Ð¾ Ð¸ ÑÐ²ÑÐ·Ð½Ð¾, ÐºÐ°Ðº Ð¶Ð¸Ð²Ð¾Ð¹ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð¶.\n",
        "ÐžÐ´Ð½Ð° Ñ†ÐµÐ»ÑŒ: Ð²Ñ‹Ð´Ð°Ñ‚ÑŒ Ð¿Ñ€Ð°Ð²Ð´Ð¾Ð¿Ð¾Ð´Ð¾Ð±Ð½ÑƒÑŽ Ñ€ÐµÐ¿Ð»Ð¸ÐºÑƒ NPC.\n",
        "ÐŸÐ¸ÑˆÐ¸ ÐºÐ°Ðº Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð¶ Ð² ÑÑ€ÐµÐ´Ð½ÐµÐ²ÐµÐºÐ¾Ð²Ð¾Ð¼/Ñ„ÑÐ½Ñ‚ÐµÐ·Ð¸Ð¹Ð½Ð¾Ð¼ Ð¼Ð¸Ñ€Ðµ.\n",
        "Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ñ‹ D&D Ð¸Ð»Ð¸ Ð±Ð»Ð¸Ð·ÐºÐ¸Ðµ Ðº ÑÑ€ÐµÐ´Ð½ÐµÐ²ÐµÐºÐ¾Ð²ÑŒÑŽ (Ñ‚Ñ€Ð°ÐºÑ‚Ð¸Ñ€, ÑÑ‚Ñ€Ð°Ð¶Ð°, Ð³Ð¸Ð»ÑŒÐ´Ð¸Ñ, Ñ…Ñ€Ð°Ð¼, Ð¼Ð°Ð³, Ð¶Ñ€ÐµÑ†, ÑÐ²Ð¸Ñ‚Ð¾Ðº, Ð°Ñ€Ð±Ð°Ð»ÐµÑ‚ Ð¸ Ñ‚.Ð¿.).\n",
        "Ð—Ð°Ð¿Ñ€ÐµÑ‰ÐµÐ½Ñ‹ ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ñ‹ Ð¸ ÐºÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ð¸: ÐºÐ¾Ð¼Ð¿ÑŒÑŽÑ‚ÐµÑ€Ñ‹, Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚, ÑÐ¼Ð°Ñ€Ñ‚Ñ„Ð¾Ð½Ñ‹, Ð»Ð°Ð·ÐµÑ€Ñ‹, Ñ€Ð°ÐºÐµÑ‚Ñ‹, ÑÐ»ÐµÐºÑ‚Ñ€Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð² ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð¼ ÑÐ¼Ñ‹ÑÐ»Ðµ, Ð¾Ð³Ð½ÐµÑÑ‚Ñ€ÐµÐ» ÐºÐ°Ðº Ð² ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð¼ Ð¼Ð¸Ñ€Ðµ.\n",
        "Ð—Ð°Ð¿Ñ€ÐµÑ‰Ñ‘Ð½ ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¹ ÑÐ»ÐµÐ½Ð³ Ð¸ Ð¼ÐµÐ¼Ñ‹.\n",
        "Ð•ÑÐ»Ð¸ Ð¸Ð³Ñ€Ð¾Ðº Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚ ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¼Ð¸ ÑÐ»Ð¾Ð²Ð°Ð¼Ð¸, Ð¿ÐµÑ€ÐµÑ„Ñ€Ð°Ð·Ð¸Ñ€ÑƒÐ¹ Ð¸Ñ… Â«Ð²Ð½ÑƒÑ‚Ñ€Ð¸ÑÐµÑ‚Ñ‚Ð¸Ð½Ð³Ð¾Ð²Ð¾Â».\n",
        "\n",
        "Ð’Ñ‹Ð²Ð¾Ð´:\n",
        "ÐžÐ´Ð½Ð° Ñ€ÐµÐ¿Ð»Ð¸ÐºÐ° (3â€“5 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ) Ð¾Ñ‚ Ð¸Ð¼ÐµÐ½Ð¸ NPC/ÐŸÐµÑ€ÑÐ¾Ð½Ð°Ð¶Ð°. ÐÐµ Ð·Ð°Ð±Ñ‹Ð²Ð°Ð¹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð¼ÐµÐ¶Ð´Ð¾Ð¼ÐµÑ‚Ð¸Ñ, Ð³Ð¾Ð²Ð¾Ñ€Ð¸ ÐºÐ°Ð»Ð¾Ñ€Ð¸Ñ‚Ð½Ð¾. Ð‘ÐµÐ· Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ð¹ Ð¸ Ð±ÐµÐ· ÑÐ»ÑƒÐ¶ÐµÐ±Ð½Ñ‹Ñ… Ð¿Ð¾Ð¼ÐµÑ‚Ð¾Ðº.\"\"\"\n",
        "\n",
        "COMBAT_PROMPT = \"\"\"Ð¢Ñ‹ â€” Ð¾Ð¿Ñ‹Ñ‚Ð½Ñ‹Ð¹ ÐœÐ°ÑÑ‚ÐµÑ€ ÐŸÐ¾Ð´Ð·ÐµÐ¼ÐµÐ»Ð¸Ð¹, ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽÑ‰Ð¸Ð¹ÑÑ Ð½Ð° ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ ÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð¸ Ð·Ð°Ñ…Ð²Ð°Ñ‚Ñ‹Ð²Ð°ÑŽÑ‰Ð¸Ñ… Ð±Ð¾Ñ‘Ð² Ð´Ð»Ñ D&D 5e. ÐÐ° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… (ÑƒÑ€Ð¾Ð²Ð½Ð¸ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð¶ÐµÐ¹, Ð¸Ñ… ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¸ ÐºÐ»Ð°ÑÑÑ‹) ÑÐ¾Ð·Ð´Ð°Ð¹ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð±Ð¾ÐµÐ²Ð¾Ð¹ Ð²ÑÑ‚Ñ€ÐµÑ‡Ð¸.\n",
        "\n",
        "Ð’Ñ‹Ð²ÐµÐ´Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð² ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ðµ â€” ÐºÐ°Ð¶Ð´Ð°Ñ ÑÐµÐºÑ†Ð¸Ñ Ð½Ð°Ñ‡Ð¸Ð½Ð°ÐµÑ‚ÑÑ Ñ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ°, Ð·Ð° ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¼ ÑÐ»ÐµÐ´ÑƒÐµÑ‚ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸Ðµ. ÐÐ¸ÐºÐ°ÐºÐ¸Ñ… Ñ‚Ð°Ð±Ð»Ð¸Ñ†, JSON, markdown Ð¸Ð»Ð¸ Ð»Ð¸ÑˆÐ½Ð¸Ñ… ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ²:\n",
        "\n",
        "Ð¡Ð»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ Ð²ÑÑ‚Ñ€ÐµÑ‡Ð¸: [ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸: Ð»Ñ‘Ð³ÐºÐ°Ñ/ÑÑ€ÐµÐ´Ð½ÑÑ/ÑÐ»Ð¾Ð¶Ð½Ð°Ñ/ÑÐ¼ÐµÑ€Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ]\n",
        "Ð’ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾Ð±ÐµÐ´Ñ‹ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹: [Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚ Ð¸ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð±Ð¾ÑÐ½Ð¾Ð²Ð°Ð½Ð¸Ðµ]\n",
        "\n",
        "ÐžÐŸÐ˜Ð¡ÐÐÐ˜Ð• Ð’Ð¡Ð¢Ð Ð•Ð§Ð˜:\n",
        "[ÐšÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¿Ñ€Ð¾Ñ‚Ð¸Ð²Ð½Ð¸ÐºÐ¾Ð²: ÐºÑ‚Ð¾ Ð¾Ð½Ð¸, Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ Ð°Ñ‚Ð°ÐºÑƒÑŽÑ‚, Ð¸Ñ… Ñ‚Ð°ÐºÑ‚Ð¸ÐºÐ° Ð² 1-2 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸ÑÑ…]\n",
        "\n",
        "ÐŸÐ ÐžÐ¢Ð˜Ð’ÐÐ˜ÐšÐ˜:\n",
        "[Ð”Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ñ‚Ð¸Ð¿Ð° Ð¿Ñ€Ð¾Ñ‚Ð¸Ð²Ð½Ð¸ÐºÐ° ÑƒÐºÐ°Ð¶Ð¸:]\n",
        "\n",
        "ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ: [Ñ€Ð°ÑÐ°/ÐºÐ»Ð°ÑÑ]\n",
        "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾: [Ñ‡Ð¸ÑÐ»Ð¾]\n",
        "ÐšÐ»Ð°ÑÑ Ð´Ð¾ÑÐ¿ÐµÑ…Ð°: [Ñ‡Ð¸ÑÐ»Ð¾]\n",
        "Ð¥Ð¸Ñ‚Ñ‹: [Ñ‡Ð¸ÑÐ»Ð¾ + ÐºÐ¾ÑÑ‚Ð¸ Ñ…Ð¸Ñ‚Ð¾Ð², Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: \"22 (3Ðº8+9)\"]\n",
        "Ð¡ÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ: [Ñ‡Ð¸ÑÐ»Ð¾ Ñ„ÑƒÑ‚Ð¾Ð²]\n",
        "ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð°Ñ‚Ð°ÐºÐ¸:\n",
        "[ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð°Ñ‚Ð°ÐºÐ¸]: [+Ðº_Ð°Ñ‚Ð°ÐºÐµ] Ðº Ð°Ñ‚Ð°ÐºÐµ, [ÑƒÑ€Ð¾Ð½+ÐºÐ¾ÑÑ‚Ð¸], Ñ‚Ð¸Ð¿ ÑƒÑ€Ð¾Ð½Ð°\n",
        "ÐžÑÐ¾Ð±Ñ‹Ðµ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚Ð¸: [Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ Ð¸ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ]\n",
        "Ð¢Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¿Ñ€Ð¸Ñ‘Ð¼Ñ‹: [2-3 Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ñ‹Ñ… Ñ…Ð¾Ð´Ð° Ð² Ð±Ð¾ÑŽ, Ð½ÐµÐ¾Ñ‡ÐµÐ²Ð¸Ð´Ð½Ñ‹Ðµ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚ÐµÐ¹]\n",
        "\n",
        "ÐžÐšÐ Ð£Ð–Ð•ÐÐ˜Ð•:\n",
        "[ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð»Ð¾ÐºÐ°Ñ†Ð¸Ð¸: Ð¿Ñ€ÐµÐ¿ÑÑ‚ÑÑ‚Ð²Ð¸Ñ, ÑƒÐºÑ€Ñ‹Ñ‚Ð¸Ñ, Ð»Ð¾Ð²ÑƒÑˆÐºÐ¸, Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ Ð¾Ð±ÑŠÐµÐºÑ‚Ñ‹]\n",
        "\n",
        "ÐÐÐ“Ð ÐÐ”Ð«:\n",
        "ÐžÐ¿Ñ‹Ñ‚: [Ð¾Ð±Ñ‰ÐµÐµ Ñ‡Ð¸ÑÐ»Ð¾ Ð¾Ð¿Ñ‹Ñ‚Ð° Ð´Ð»Ñ Ñ€Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ñ Ð¼ÐµÐ¶Ð´Ñƒ Ð¸Ð³Ñ€Ð¾ÐºÐ°Ð¼Ð¸]\n",
        "Ð¡Ð¾ÐºÑ€Ð¾Ð²Ð¸Ñ‰Ð°: [Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚Ñ‹, Ð·Ð¾Ð»Ð¾Ñ‚Ð¾, Ð¼Ð°Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚Ñ‹]\n",
        "ÐžÑÐ¾Ð±Ñ‹Ðµ Ð½Ð°Ð³Ñ€Ð°Ð´Ñ‹: [Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ, ÑÐ¾ÑŽÐ·Ð½Ð¸ÐºÐ¸, Ð¿Ñ€ÐµÐ¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð° Ð´Ð»Ñ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ñ… ÐºÐ²ÐµÑÑ‚Ð¾Ð²]\n",
        "\n",
        "Ð¡ÐžÐ’Ð•Ð¢Ð« ÐœÐÐ¡Ð¢Ð•Ð Ð£:\n",
        "\n",
        "Ð‘Ð°Ð»Ð°Ð½Ñ: [Ñ‡Ñ‚Ð¾ Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ/ÑƒÐ±Ñ€Ð°Ñ‚ÑŒ, ÐµÑÐ»Ð¸ Ð±Ð¾Ð¹ ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð»Ñ‘Ð³ÐºÐ¸Ð¹ Ð¸Ð»Ð¸ ÑÐ»Ð¾Ð¶Ð½Ñ‹Ð¹]\n",
        "ÐÑ‚Ð¼Ð¾ÑÑ„ÐµÑ€Ð°: [ÐºÐ°Ðº Ð¾Ð¿Ð¸ÑÐ°Ñ‚ÑŒ Ð½Ð°Ñ‡Ð°Ð»Ð¾ Ð±Ð¾Ñ Ð¸ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚Ñ‹]\n",
        "ÐÐ»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ñ‹: [Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ñ‹ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ Ð±Ð¾Ñ Ð¿Ð¾Ð¼Ð¸Ð¼Ð¾ ÑƒÐ±Ð¸Ð¹ÑÑ‚Ð²Ð° Ð²ÑÐµÑ… Ð¿Ñ€Ð¾Ñ‚Ð¸Ð²Ð½Ð¸ÐºÐ¾Ð²]\n",
        "Ð’Ð°Ð¶Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸: [ÐºÐ°ÐºÐ¸Ðµ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ð½Ð°Ð²Ñ‹ÐºÐ¾Ð² Ð¸Ð·Ð¼ÐµÐ½ÑÑ‚ Ñ…Ð¾Ð´ Ð±Ð¾Ñ]\n",
        "\n",
        "Ð”ÐžÐŸÐžÐ›ÐÐ˜Ð¢Ð•Ð›Ð¬ÐÐž:\n",
        "[ÐŸÐ¾Ð»ÐµÐ·Ð½Ñ‹Ðµ Ð¿Ñ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ñ: Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ðµ Ð¿Ð¾ÑÐ»ÐµÐ´ÑÑ‚Ð²Ð¸Ñ Ð±Ð¾Ñ, ÑÐ²ÑÐ·ÑŒ Ñ ÑÑŽÐ¶ÐµÑ‚Ð¾Ð¼, Ñ€ÐµÐ°ÐºÑ†Ð¸Ñ NPC Ð¿Ð¾ÑÐ»Ðµ Ð±Ð¾Ñ]\"\"\"\n",
        "\n",
        "PLAYER_RULES_PROMPT = \"\"\"Ð¢Ñ‹ â€” Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð¸Ð³Ñ€Ð¾ÐºÐ° D&D 5e. ÐžÑ‚Ð²ÐµÑ‚ÑŒ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°Ð¼ Ð¸ Ð¼ÐµÑ…Ð°Ð½Ð¸ÐºÐ°Ð¼.\n",
        "\n",
        "Ð¢ÐµÐ±Ðµ Ð±ÑƒÐ´ÐµÑ‚ Ð´Ð°Ð½Ð¾:\n",
        "1) Ð’Ð¾Ð¿Ñ€Ð¾Ñ Ð¸Ð³Ñ€Ð¾ÐºÐ°\n",
        "2) (ÐžÐ¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾) Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ñ‹ Ð¸Ð· Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹ Ð¸Ð³Ñ€Ð¾ÐºÐ°\n",
        "\n",
        "Ð•ÑÐ»Ð¸ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ñ‹ ÐµÑÑ‚ÑŒ â€” Ð¾Ð¿Ð¸Ñ€Ð°Ð¹ÑÑ Ð½Ð° Ð½Ð¸Ñ…. Ð•ÑÐ»Ð¸ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð¾Ð² Ð½ÐµÑ‚ â€” Ð¾Ñ‚Ð²ÐµÑ‚ÑŒ Ð¿Ð¾ Ð¾Ð±Ñ‰Ð¸Ð¼ Ð·Ð½Ð°Ð½Ð¸ÑÐ¼ D&D 5e.\n",
        "\n",
        "ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ:\n",
        "ÐÐµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ ÐºÐ°Ð¿ÑÐ¾Ð¼.\n",
        "ÐÐµ Ð¿Ð¸ÑˆÐ¸ ÑÐ»ÑƒÐ¶ÐµÐ±Ð½Ñ‹Ðµ Ñ„Ð»Ð°Ð³Ð¸ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, \"found\", \"Ñ„Ð»Ð°Ð³\", \"ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚\", \"Ð±Ð°Ð·Ð°: Ð´Ð°/Ð½ÐµÑ‚\").\n",
        "ÐÐµ Ð¿Ñ€Ð¸Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ð¹ Ð´ÐµÑ‚Ð°Ð»Ð¸ ÐºÐ°Ð¼Ð¿Ð°Ð½Ð¸Ð¸.\n",
        "\n",
        "Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ð²Ñ‹Ð²Ð¾Ð´Ð°:\n",
        "Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ (1â€“2 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ).\n",
        "ÐŸÐ¾Ñ‚Ð¾Ð¼ Ð¿ÑƒÑÑ‚Ð°Ñ ÑÑ‚Ñ€Ð¾ÐºÐ°.\n",
        "ÐŸÐ¾Ñ‚Ð¾Ð¼ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ð¾Ðµ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ðµ (6â€“10 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹).\n",
        "ÐŸÐ¾Ñ‚Ð¾Ð¼ (ÐµÑÐ»Ð¸ ÑƒÐ¼ÐµÑÑ‚Ð½Ð¾) Ð¿ÑƒÑÑ‚Ð°Ñ ÑÑ‚Ñ€Ð¾ÐºÐ° Ð¸ ÑÑ‚Ñ€Ð¾ÐºÐ° \"ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð² Ð¸Ð³Ñ€Ðµ: ...\".\n",
        "\"\"\"\n",
        "\n",
        "PLAYER_SITUATION_PROMPT = \"\"\"Ð¢Ñ‹ â€” Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð¸Ð³Ñ€Ð¾ÐºÐ° D&D 5e. ÐŸÐ¾Ð¼Ð¾Ð³Ð¸ Ñ€Ð°Ð·Ð¾Ð±Ñ€Ð°Ñ‚ÑŒÑÑ Ð² ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ð¸Ð¸ Ð·Ð° ÑÑ‚Ð¾Ð»Ð¾Ð¼.\n",
        "\n",
        "Ð¢ÐµÐ±Ðµ Ð±ÑƒÐ´ÐµÑ‚ Ð´Ð°Ð½Ð¾:\n",
        "1) ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ð¸Ð¸ Ð¸Ð³Ñ€Ð¾ÐºÐ¾Ð¼\n",
        "2) (ÐžÐ¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾) Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ñ‹ Ð¸Ð· Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹ Ð¸Ð³Ñ€Ð¾ÐºÐ°\n",
        "\n",
        "Ð•ÑÐ»Ð¸ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ñ‹ ÐµÑÑ‚ÑŒ â€” Ð¾Ð¿Ð¸Ñ€Ð°Ð¹ÑÑ Ð½Ð° Ð½Ð¸Ñ…. Ð•ÑÐ»Ð¸ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð¾Ð² Ð½ÐµÑ‚ â€” Ð¿Ð¾Ð¼Ð¾Ð³Ð¸ Ð¿Ð¾ Ð¾Ð±Ñ‰Ð¸Ð¼ Ð·Ð½Ð°Ð½Ð¸ÑÐ¼ D&D 5e.\n",
        "\n",
        "ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ:\n",
        "ÐÐµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ ÐºÐ°Ð¿ÑÐ¾Ð¼.\n",
        "ÐÐµ Ð¿Ð¸ÑˆÐ¸ ÑÐ»ÑƒÐ¶ÐµÐ±Ð½Ñ‹Ðµ Ñ„Ð»Ð°Ð³Ð¸ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, \"found\", \"Ñ„Ð»Ð°Ð³\", \"ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚\", \"Ð±Ð°Ð·Ð°: Ð´Ð°/Ð½ÐµÑ‚\").\n",
        "ÐÐµ Ð¿Ñ€Ð¸Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ð¹ Ð´ÐµÑ‚Ð°Ð»Ð¸ ÐºÐ°Ð¼Ð¿Ð°Ð½Ð¸Ð¸.\n",
        "\n",
        "Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ð²Ñ‹Ð²Ð¾Ð´Ð°:\n",
        "Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ°Ñ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ñ (1â€“2 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ).\n",
        "ÐŸÐ¾Ñ‚Ð¾Ð¼ Ð¿ÑƒÑÑ‚Ð°Ñ ÑÑ‚Ñ€Ð¾ÐºÐ°.\n",
        "ÐŸÐ¾Ñ‚Ð¾Ð¼ Ñ€Ð°Ð·Ð±Ð¾Ñ€ Ð¿Ð¾ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°Ð¼ Ð¸ Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ ÑÐ¾Ð²ÐµÑ‚ (8â€“12 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹).\n",
        "ÐŸÐ¾Ñ‚Ð¾Ð¼ (ÐµÑÐ»Ð¸ ÑƒÐ¼ÐµÑÑ‚Ð½Ð¾) Ð¿ÑƒÑÑ‚Ð°Ñ ÑÑ‚Ñ€Ð¾ÐºÐ° Ð¸ ÑÑ‚Ñ€Ð¾ÐºÐ° \"ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð² Ð¸Ð³Ñ€Ðµ: ...\".\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PLAYER FAISS RAG (Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð°Ñ Ð±Ð°Ð·Ð°, Ð±ÐµÐ· Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð° Ðº Ð´Ð°Ð½Ð½Ñ‹Ð¼ DM)\n",
        "import os\n",
        "import re\n",
        "import gc\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import Optional, Tuple, List, Iterator\n",
        "\n",
        "logger = logging.getLogger(\"rag-dnd-bot-faiss\")\n",
        "\n",
        "PLAYER_DATASET_DIR = Path(os.getenv(\"PLAYER_DATASET_DIR\", \"Dataset/Main\"))\n",
        "PLAYER_FAISS_DIR = Path(os.getenv(\"PLAYER_FAISS_DIR\", \"artifacts/faiss_player_knowledge\"))\n",
        "PLAYER_FALLBACK_EMBED_MODEL = os.getenv(\"PLAYER_FALLBACK_EMBED_MODEL\", \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
        "PLAYER_EMBED_MODEL = os.getenv(\"PLAYER_EMBED_MODEL\", PLAYER_FALLBACK_EMBED_MODEL)\n",
        "PLAYER_CHUNK_SIZE = int(os.getenv(\"PLAYER_CHUNK_SIZE\", \"2000\"))\n",
        "PLAYER_CHUNK_OVERLAP = int(os.getenv(\"PLAYER_CHUNK_OVERLAP\", \"500\"))\n",
        "PLAYER_TOP_K = int(os.getenv(\"PLAYER_TOP_K\", \"15\"))\n",
        "PLAYER_STREAM_FILE_BYTES = int(os.getenv(\"PLAYER_STREAM_FILE_BYTES\", str(5 * 1024 * 1024)))\n",
        "\n",
        "\n",
        "def _normalize_text_player(text: str) -> str:\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
        "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def _iter_char_chunks_from_stream(stream, *, chunk_size: int, overlap: int) -> Iterator[str]:\n",
        "    buf = \"\"\n",
        "    step = max(1, chunk_size - overlap)\n",
        "    while True:\n",
        "        part = stream.read(64 * 1024)\n",
        "        if not part:\n",
        "            break\n",
        "        buf += part\n",
        "        while len(buf) >= chunk_size:\n",
        "            yield buf[:chunk_size]\n",
        "            buf = buf[step:]\n",
        "\n",
        "    tail = buf.strip()\n",
        "    if tail:\n",
        "        yield tail\n",
        "\n",
        "\n",
        "def _ocr_pdf_to_txt(pdf_path: Path, out_txt_path: Path) -> Tuple[bool, str]:\n",
        "    \"\"\"OCR PDF -> TXT. Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ (ok, message). ÐŸÐ¸ÑˆÐµÑ‚ TXT Ñ€ÑÐ´Ð¾Ð¼ Ñ PDF.\"\"\"\n",
        "    try:\n",
        "        import pymupdf\n",
        "    except Exception as e:\n",
        "        return False, f\"pymupdf Ð½Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½: {e}\"\n",
        "\n",
        "    try:\n",
        "        import pytesseract\n",
        "        from PIL import Image\n",
        "    except Exception as e:\n",
        "        return False, f\"pytesseract/PIL Ð½Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹: {e}\"\n",
        "\n",
        "    try:\n",
        "        doc = pymupdf.open(str(pdf_path))\n",
        "    except Exception as e:\n",
        "        return False, f\"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚ÑŒ PDF: {e}\"\n",
        "\n",
        "    parts: List[str] = []\n",
        "    try:\n",
        "        for page_num in range(doc.page_count):\n",
        "            page = doc.load_page(page_num)\n",
        "            pix = page.get_pixmap(dpi=300)\n",
        "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
        "            text = pytesseract.image_to_string(img, lang=os.getenv(\"OCR_LANG\", \"rus+eng\"))\n",
        "            text = _normalize_text_player(text)\n",
        "            if text:\n",
        "                parts.append(text)\n",
        "            if page_num % 5 == 0:\n",
        "                gc.collect()\n",
        "    except Exception as e:\n",
        "        return False, f\"OCR Ð¾ÑˆÐ¸Ð±ÐºÐ°: {e}\"\n",
        "    finally:\n",
        "        doc.close()\n",
        "\n",
        "    full = \"\\n\\n\".join(parts).strip()\n",
        "    if not full:\n",
        "        return False, \"OCR Ð½Ðµ Ð¸Ð·Ð²Ð»Ñ‘Ðº Ñ‚ÐµÐºÑÑ‚ (Ð¿ÑƒÑÑ‚Ð¾)\"\n",
        "\n",
        "    try:\n",
        "        out_txt_path.write_text(full, encoding=\"utf-8\", errors=\"ignore\")\n",
        "    except Exception as e:\n",
        "        return False, f\"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐ¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ TXT: {e}\"\n",
        "\n",
        "    return True, f\"OK: {out_txt_path.name}\"\n",
        "\n",
        "\n",
        "class PlayerKnowledgeBase:\n",
        "    def __init__(self, dataset_dir: Path = PLAYER_DATASET_DIR, faiss_dir: Path = PLAYER_FAISS_DIR, embed_model: Optional[str] = None):\n",
        "        self.dataset_dir = Path(dataset_dir)\n",
        "        self.faiss_dir = Path(faiss_dir)\n",
        "        self.embed_model = embed_model or PLAYER_EMBED_MODEL\n",
        "        self._vectorstore = None\n",
        "        self._embeddings = None\n",
        "        self._splitter = None\n",
        "        self.last_status = \"init\"\n",
        "        self.faiss_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def _get_embeddings(self):\n",
        "        if self._embeddings is None:\n",
        "            from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "            device = \"cuda\" if os.getenv(\"USE_CUDA\", \"0\") == \"1\" else \"cpu\"\n",
        "            self._embeddings = HuggingFaceEmbeddings(\n",
        "                model_name=self.embed_model,\n",
        "                model_kwargs={\"device\": device},\n",
        "                encode_kwargs={\"normalize_embeddings\": True},\n",
        "            )\n",
        "            logger.info(\"Player embeddings initialized (%s) on %s\", self.embed_model, device)\n",
        "        return self._embeddings\n",
        "\n",
        "    def _reset_embeddings(self, embed_model: str):\n",
        "        self.embed_model = embed_model\n",
        "        self._embeddings = None\n",
        "\n",
        "    def _get_splitter(self):\n",
        "        if self._splitter is None:\n",
        "            from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "            self._splitter = RecursiveCharacterTextSplitter(\n",
        "                chunk_size=PLAYER_CHUNK_SIZE,\n",
        "                chunk_overlap=PLAYER_CHUNK_OVERLAP,\n",
        "                separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "            )\n",
        "        return self._splitter\n",
        "\n",
        "    def _load_vectorstore_if_exists(self):\n",
        "        if self._vectorstore is not None:\n",
        "            return self._vectorstore\n",
        "\n",
        "        index_file = self.faiss_dir / \"index.faiss\"\n",
        "        if not index_file.exists():\n",
        "            return None\n",
        "\n",
        "        from langchain_community.vectorstores import FAISS\n",
        "\n",
        "        try:\n",
        "            self._vectorstore = FAISS.load_local(\n",
        "                str(self.faiss_dir),\n",
        "                self._get_embeddings(),\n",
        "                allow_dangerous_deserialization=True,\n",
        "            )\n",
        "            logger.info(\"Player FAISS index loaded from %s\", self.faiss_dir)\n",
        "            return self._vectorstore\n",
        "        except Exception as e:\n",
        "            logger.exception(\"Player FAISS load failed with %s\", self.embed_model)\n",
        "\n",
        "        # Fallback: ÐµÑÐ»Ð¸ Ð¸Ð½Ð´ÐµÐºÑ ÑÐ¾Ð±Ñ€Ð°Ð½ Ð´Ñ€ÑƒÐ³Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»ÑŒÑŽ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€ mpnet), Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ ÐµÑŽ\n",
        "        try:\n",
        "            self._reset_embeddings(PLAYER_FALLBACK_EMBED_MODEL)\n",
        "            self._vectorstore = FAISS.load_local(\n",
        "                str(self.faiss_dir),\n",
        "                self._get_embeddings(),\n",
        "                allow_dangerous_deserialization=True,\n",
        "            )\n",
        "            logger.info(\"Player FAISS index loaded with fallback model (%s)\", self.embed_model)\n",
        "            return self._vectorstore\n",
        "        except Exception:\n",
        "            logger.exception(\"Player FAISS load failed even with fallback model\")\n",
        "            self._vectorstore = None\n",
        "            return None\n",
        "\n",
        "    def _save_vectorstore(self):\n",
        "        if self._vectorstore is not None:\n",
        "            self._vectorstore.save_local(str(self.faiss_dir))\n",
        "\n",
        "    def _iter_source_files(self) -> List[Path]:\n",
        "        if not self.dataset_dir.exists():\n",
        "            return []\n",
        "        files: List[Path] = []\n",
        "        for fp in sorted(self.dataset_dir.rglob(\"*\")):\n",
        "            if not fp.is_file():\n",
        "                continue\n",
        "            if fp.suffix.lower() in (\".txt\", \".md\", \".rst\", \".csv\", \".pdf\"):\n",
        "                files.append(fp)\n",
        "        return files\n",
        "\n",
        "    def ocr_pdfs_to_txt(self) -> str:\n",
        "        if not self.dataset_dir.exists():\n",
        "            return f\"Dataset Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½: {self.dataset_dir}\"\n",
        "\n",
        "        pdfs = [p for p in self._iter_source_files() if p.suffix.lower() == \".pdf\"]\n",
        "        if not pdfs:\n",
        "            return \"PDF Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð´Ð»Ñ OCR.\"\n",
        "\n",
        "        ok = 0\n",
        "        fail = 0\n",
        "        notes = []\n",
        "        for pdf in pdfs:\n",
        "            out_txt = pdf.with_suffix(\".txt\")\n",
        "            if out_txt.exists() and out_txt.stat().st_size > 200:\n",
        "                continue\n",
        "            done, msg = _ocr_pdf_to_txt(pdf, out_txt)\n",
        "            if done:\n",
        "                ok += 1\n",
        "            else:\n",
        "                fail += 1\n",
        "                notes.append(f\"{pdf.name}: {msg}\")\n",
        "\n",
        "        suffix = \"\" if not notes else (\"\\n\" + \"\\n\".join(notes[:10]))\n",
        "        return f\"OCR Ð³Ð¾Ñ‚Ð¾Ð²Ð¾. Ð£ÑÐ¿ÐµÑˆÐ½Ð¾: {ok}, Ð¾ÑˆÐ¸Ð±Ð¾Ðº: {fail}.\" + suffix\n",
        "\n",
        "    def build_or_rebuild_index(self, *, force: bool = False) -> str:\n",
        "        from langchain_community.vectorstores import FAISS\n",
        "\n",
        "        self.last_status = \"build_start\"\n",
        "\n",
        "        if force:\n",
        "            self._vectorstore = None\n",
        "            for fp in self.faiss_dir.glob(\"*\"):\n",
        "                try:\n",
        "                    fp.unlink()\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "        self.ocr_pdfs_to_txt()\n",
        "\n",
        "        txts = [p for p in self._iter_source_files() if p.suffix.lower() in (\".txt\", \".md\", \".rst\", \".csv\")]\n",
        "        if not txts:\n",
        "            self.last_status = \"dataset_empty\"\n",
        "            return f\"ÐÐµÑ‚ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð´Ð»Ñ Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ð¸ Ð² {self.dataset_dir}\"\n",
        "\n",
        "        splitter = self._get_splitter()\n",
        "        docs_total = 0\n",
        "        files_used = 0\n",
        "        files_skipped = 0\n",
        "        vs = None\n",
        "\n",
        "        for i, fp in enumerate(txts):\n",
        "            try:\n",
        "                size = fp.stat().st_size\n",
        "            except Exception:\n",
        "                size = 0\n",
        "\n",
        "            try:\n",
        "                if size >= PLAYER_STREAM_FILE_BYTES:\n",
        "                    with fp.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "                        for chunk_id, chunk in enumerate(_iter_char_chunks_from_stream(f, chunk_size=PLAYER_CHUNK_SIZE, overlap=PLAYER_CHUNK_OVERLAP)):\n",
        "                            text = _normalize_text_player(chunk)\n",
        "                            if not text or len(text) < 50:\n",
        "                                continue\n",
        "                            docs = splitter.create_documents(\n",
        "                                [text],\n",
        "                                metadatas=[{\"source_file\": fp.name, \"rel_path\": str(fp.relative_to(self.dataset_dir)), \"chunk_id\": chunk_id}],\n",
        "                            )\n",
        "                            if not docs:\n",
        "                                continue\n",
        "                            if vs is None:\n",
        "                                vs = FAISS.from_documents(docs, self._get_embeddings())\n",
        "                            else:\n",
        "                                vs.add_documents(docs)\n",
        "                            docs_total += len(docs)\n",
        "                            if docs_total % 200 == 0:\n",
        "                                gc.collect()\n",
        "                    files_used += 1\n",
        "                else:\n",
        "                    raw = fp.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "                    text = _normalize_text_player(raw)\n",
        "                    if not text or len(text) < 50:\n",
        "                        files_skipped += 1\n",
        "                        continue\n",
        "                    docs = splitter.create_documents([text], metadatas=[{\"source_file\": fp.name, \"rel_path\": str(fp.relative_to(self.dataset_dir))}])\n",
        "                    if not docs:\n",
        "                        files_skipped += 1\n",
        "                        continue\n",
        "                    if vs is None:\n",
        "                        vs = FAISS.from_documents(docs, self._get_embeddings())\n",
        "                    else:\n",
        "                        vs.add_documents(docs)\n",
        "                    docs_total += len(docs)\n",
        "                    files_used += 1\n",
        "\n",
        "                if i % 5 == 0:\n",
        "                    gc.collect()\n",
        "\n",
        "            except Exception as e:\n",
        "                files_skipped += 1\n",
        "                logger.exception(\"Player index build: failed for %s\", fp)\n",
        "                self.last_status = f\"build_error:{fp.name}:{e}\"\n",
        "\n",
        "        if vs is None or docs_total == 0:\n",
        "            self.last_status = \"index_empty\"\n",
        "            return \"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¸Ð½Ð´ÐµÐºÑ: Ð½ÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð¾ÑÐ»Ðµ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸\"\n",
        "\n",
        "        self._vectorstore = vs\n",
        "        self._save_vectorstore()\n",
        "        self.last_status = \"ready\"\n",
        "        return f\"Player Ð¸Ð½Ð´ÐµÐºÑ Ð¿Ð¾ÑÑ‚Ñ€Ð¾ÐµÐ½: {docs_total} Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð¾Ð². Ð¤Ð°Ð¹Ð»Ð¾Ð² Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾: {files_used}, Ð¿Ñ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ð¾: {files_skipped}. ÐŸÑƒÑ‚ÑŒ: {self.faiss_dir}\"\n",
        "\n",
        "    def search(self, query: str, *, top_k: int = PLAYER_TOP_K) -> Tuple[bool, str]:\n",
        "        self.last_status = \"search\"\n",
        "        vs = self._load_vectorstore_if_exists()\n",
        "        if vs is None:\n",
        "            self.last_status = \"index_missing\"\n",
        "            return False, \"\"\n",
        "\n",
        "        try:\n",
        "            ntotal = int(getattr(vs, \"index\").ntotal)\n",
        "        except Exception:\n",
        "            ntotal = None\n",
        "\n",
        "        if ntotal == 0:\n",
        "            self.last_status = \"index_empty\"\n",
        "            return False, \"\"\n",
        "\n",
        "        docs = vs.similarity_search(query, k=top_k)\n",
        "        if not docs:\n",
        "            self.last_status = \"no_docs\"\n",
        "            return False, \"\"\n",
        "\n",
        "        contexts = []\n",
        "        for d in docs:\n",
        "            meta = d.metadata or {}\n",
        "            src = meta.get(\"rel_path\") or meta.get(\"source_file\") or \"unknown\"\n",
        "            body = (d.page_content or \"\").strip()\n",
        "            if not body:\n",
        "                continue\n",
        "            contexts.append(f\"[{src}]\\n\" + body)\n",
        "\n",
        "        if not contexts:\n",
        "            self.last_status = \"no_text\"\n",
        "            return False, \"\"\n",
        "\n",
        "        self.last_status = \"found\"\n",
        "        return True, \"\\n\\n---\\n\\n\".join(contexts)\n",
        "\n",
        "\n",
        "player_kb = PlayerKnowledgeBase()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-14 20:17:10,467 INFO Bot started\n",
            "2026-01-14 20:17:10,867 INFO HTTP Request: POST https://api.telegram.org/bot1/getMe \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:10,942 INFO HTTP Request: POST https://api.telegram.org/bot1/deleteWebhook \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:10,945 INFO Application started\n",
            "2026-01-14 20:17:11,300 INFO HTTP Request: POST https://api.telegram.org/bot1/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:11,469 INFO HTTP Request: POST https://api.telegram.org/bot1/sendMessage \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:15,606 INFO HTTP Request: POST https://api.telegram.org/bot1/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:15,724 INFO HTTP Request: POST https://api.telegram.org/bot1/sendMessage \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:16,644 INFO HTTP Request: POST https://api.telegram.org/bot1/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:16,758 INFO HTTP Request: POST https://api.telegram.org/bot1/sendMessage \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:18,301 INFO HTTP Request: POST https://api.telegram.org/bot1/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:18,465 INFO HTTP Request: POST https://api.telegram.org/bot1/sendMessage \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:20,777 INFO HTTP Request: POST https://api.telegram.org/bot1/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:20,977 INFO HTTP Request: POST https://api.telegram.org/bot1/sendMessage \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:22,725 INFO HTTP Request: POST https://api.telegram.org/bot1/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:22,873 INFO HTTP Request: POST https://api.telegram.org/bot1/sendMessage \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:23,677 INFO HTTP Request: POST https://api.telegram.org/bot1/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:23,903 INFO HTTP Request: POST https://api.telegram.org/bot1/sendMessage \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:28,222 INFO HTTP Request: POST https://api.telegram.org/bot1/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:28,345 INFO HTTP Request: POST https://api.telegram.org/bot1/sendMessage \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:29,747 INFO HTTP Request: POST https://api.telegram.org/bot1/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:29,905 INFO HTTP Request: POST https://api.telegram.org/bot1/sendMessage \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "# FAISS Telegram bot (compact). Run this cell.\n",
        "import os, re, time, json, asyncio, logging\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from telegram import ReplyKeyboardMarkup, KeyboardButton, Update\n",
        "from telegram.ext import ApplicationBuilder, ContextTypes, MessageHandler, CommandHandler, filters\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\n",
        "logger = logging.getLogger(\"rag-dnd-bot\")\n",
        "\n",
        "# ----------------- Config -----------------\n",
        "TG_BOT_TOKEN = os.getenv(\"TG_BOT_TOKEN\")\n",
        "OLLAMA_API_URL = os.getenv(\"OLLAMA_API_URL\", \"https://ollama.com/api/chat\")\n",
        "OLLAMA_API_KEY = os.getenv(\"OLLAMA_API_KEY\")\n",
        "OLLAMA_MODEL = os.getenv(\"OLLAMA_MODEL\", \"gpt-oss:20b-cloud\")\n",
        "\n",
        "OLLAMA_TEMPERATURE = float(os.getenv(\"OLLAMA_TEMPERATURE\", \"0.6\"))\n",
        "OLLAMA_TEMPERATURE_REPLIES = float(os.getenv(\"OLLAMA_TEMPERATURE_REPLIES\", \"0.2\"))\n",
        "\n",
        "OLLAMA_NUM_PREDICT = int(os.getenv(\"OLLAMA_NUM_PREDICT\", \"900\"))\n",
        "OLLAMA_NUM_PREDICT_REPLIES = int(os.getenv(\"OLLAMA_NUM_PREDICT_REPLIES\", \"450\"))\n",
        "\n",
        "TELEGRAM_MAX_CHARS = int(os.getenv(\"TELEGRAM_MAX_CHARS\", \"3800\"))\n",
        "\n",
        "FAISS_DIR = Path(os.getenv(\"FAISS_DIR\", \"artifacts/faiss_campaign_knowledge\"))\n",
        "\n",
        "VOICE_MALE = \"male\"\n",
        "VOICE_FEMALE = \"female\"\n",
        "\n",
        "# ----------------- Keyboards -----------------\n",
        "KB_MAIN = ReplyKeyboardMarkup(\n",
        "    [[KeyboardButton(\"Dungeon Master ðŸ§™â€â™‚ï¸\"), KeyboardButton(\"Player ðŸŽ²\"), KeyboardButton(\"Restart ðŸ”„\")]],\n",
        "    resize_keyboard=True,\n",
        ")\n",
        "KB_PLAYER = ReplyKeyboardMarkup(\n",
        "    [[KeyboardButton(\"Ð’Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¿Ð¾ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°Ð¼\"), KeyboardButton(\"ÐŸÐ¾Ð¼Ð¾Ñ‰ÑŒ Ð² ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ð¸Ð¸\")], [KeyboardButton(\"â† Ð“Ð»Ð°Ð²Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ\")]],\n",
        "    resize_keyboard=True,\n",
        ")\n",
        "KB_DM = ReplyKeyboardMarkup(\n",
        "    [\n",
        "        [KeyboardButton(\"Ð¥Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ Ð·Ð½Ð°Ð½Ð¸Ð¹\"), KeyboardButton(\"Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð¶Ð°\")],\n",
        "        [KeyboardButton(\"Ð ÐµÐ¿Ð»Ð¸ÐºÐ¸\"), KeyboardButton(\"Ð‘Ð¾ÐµÐ²ÐºÐ°\")],\n",
        "        [KeyboardButton(\"Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ\")],\n",
        "        [KeyboardButton(\"â† Ð“Ð»Ð°Ð²Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ\")],\n",
        "    ],\n",
        "    resize_keyboard=True,\n",
        ")\n",
        "KB_REPLIES = ReplyKeyboardMarkup(\n",
        "    [[KeyboardButton(\"Ð¢ÐµÐºÑÑ‚\"), KeyboardButton(\"ÐžÐ·Ð²ÑƒÑ‡ÐºÐ° + Ñ‚ÐµÐºÑÑ‚\")], [KeyboardButton(\"â† ÐÐ°Ð·Ð°Ð´ (DM)\")]],\n",
        "    resize_keyboard=True,\n",
        ")\n",
        "KB_VOICE = ReplyKeyboardMarkup(\n",
        "    [[KeyboardButton(\"ÐœÑƒÐ¶ÑÐºÐ¾Ð¹\"), KeyboardButton(\"Ð–ÐµÐ½ÑÐºÐ¸Ð¹\")], [KeyboardButton(\"â† ÐÐ°Ð·Ð°Ð´ (DM)\")]],\n",
        "    resize_keyboard=True,\n",
        ")\n",
        "\n",
        "WELCOME_TEXT = \"ðŸŽ² RAG DnD Assistant\\nÐ’Ñ‹Ð±ÐµÑ€Ð¸ Ñ€Ð¾Ð»ÑŒ.\"\n",
        "\n",
        "# ----------------- Helpers -----------------\n",
        "def normalize_text(text: str) -> str:\n",
        "    text = (text or \"\").replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
        "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def chunk_for_tg(text: str, max_chars: int = TELEGRAM_MAX_CHARS):\n",
        "    t = (text or \"\").strip()\n",
        "    if not t:\n",
        "        return [\"\"]\n",
        "    out = []\n",
        "    while t:\n",
        "        if len(t) <= max_chars:\n",
        "            out.append(t)\n",
        "            break\n",
        "        cut = t.rfind(\"\\n\\n\", 0, max_chars)\n",
        "        if cut < max_chars * 0.4:\n",
        "            cut = t.rfind(\"\\n\", 0, max_chars)\n",
        "        if cut < max_chars * 0.4:\n",
        "            cut = t.rfind(\" \", 0, max_chars)\n",
        "        if cut < max_chars * 0.4:\n",
        "            cut = max_chars\n",
        "        out.append(t[:cut].rstrip())\n",
        "        t = t[cut:].lstrip()\n",
        "    return out\n",
        "\n",
        "\n",
        "async def safe_reply(update: Update, text: str, *, reply_markup=None):\n",
        "    for i, part in enumerate(chunk_for_tg(text)):\n",
        "        if i == 0:\n",
        "            await update.message.reply_text(part, reply_markup=reply_markup)\n",
        "        else:\n",
        "            await update.message.reply_text(part)\n",
        "\n",
        "\n",
        "def _looks_like_bad_reply(text: str) -> bool:\n",
        "    t = normalize_text(text)\n",
        "    if not t:\n",
        "        return True\n",
        "    if len(t) > 700:\n",
        "        return True\n",
        "    low = t.lower()\n",
        "    bad_words = [\"Ð·Ð°ÑˆÐºÐ²Ð°Ñ€\", \"ÐºÑ€Ð¸Ð½Ð¶\", \"Ñ€Ð¾Ñ„Ð»\", \"Ð»Ð¾Ð»\", \"Ð¼ÐµÐ¼\", \"Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚\", \"ÑÐ¼Ð°Ñ€Ñ‚Ñ„Ð¾Ð½\", \"ÐºÐ¾Ð¼Ð¿ÑŒÑŽÑ‚ÐµÑ€\", \"Ð»Ð°Ð·ÐµÑ€\", \"Ñ€Ð°ÐºÐµÑ‚Ð°\", \"ÑÐ»ÐµÐºÑ‚Ñ€Ð¸Ñ‡\"]\n",
        "    return any(w in low for w in bad_words)\n",
        "\n",
        "\n",
        "def _player_warning(found: bool) -> str:\n",
        "    if found:\n",
        "        return \"\"\n",
        "    return \"Ð¯ Ð½Ðµ Ð½Ð°ÑˆÑ‘Ð» Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸Ñ… Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð¾Ð² Ð² Ð±Ð°Ð·Ðµ Ð·Ð½Ð°Ð½Ð¸Ð¹ Ð¸Ð³Ñ€Ð¾ÐºÐ°; Ð¾Ñ‚Ð²ÐµÑ‚ Ð½Ð¸Ð¶Ðµ â€” Ð¿Ð¾ Ð¾Ð±Ñ‰Ð¸Ð¼ Ð·Ð½Ð°Ð½Ð¸ÑÐ¼ D&D 5e.\"\n",
        "\n",
        "\n",
        "# ----------------- Ollama -----------------\n",
        "class OllamaCloud:\n",
        "    def __init__(self):\n",
        "        self.url = OLLAMA_API_URL\n",
        "        self.model = OLLAMA_MODEL\n",
        "        self.key = OLLAMA_API_KEY\n",
        "\n",
        "    def chat(self, messages, *, num_predict: int, temperature: float, timeout: int = 120) -> str:\n",
        "        import requests\n",
        "\n",
        "        headers = {\"Content-Type\": \"application/json\"}\n",
        "        if self.key:\n",
        "            headers[\"Authorization\"] = \"Bearer \" + self.key\n",
        "\n",
        "        body = {\n",
        "            \"model\": self.model,\n",
        "            \"messages\": messages,\n",
        "            \"stream\": False,\n",
        "            \"options\": {\"num_predict\": int(num_predict), \"temperature\": float(temperature)},\n",
        "        }\n",
        "        r = requests.post(self.url, json=body, headers=headers, timeout=timeout)\n",
        "        r.raise_for_status()\n",
        "        data = r.json() if r.content else {}\n",
        "        msg = (data.get(\"message\") or {})\n",
        "        content = msg.get(\"content\")\n",
        "        if isinstance(content, str) and content.strip():\n",
        "            return content.strip()\n",
        "        resp = data.get(\"response\")\n",
        "        if isinstance(resp, str) and resp.strip():\n",
        "            return resp.strip()\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def ollama_with_retries(ollama: OllamaCloud, messages, *, num_predict: int, temperature: float, retries: int = 2) -> str:\n",
        "    for i in range(retries + 1):\n",
        "        try:\n",
        "            out = (ollama.chat(messages, num_predict=num_predict, temperature=temperature) or \"\").strip()\n",
        "            if out:\n",
        "                return out\n",
        "        except Exception:\n",
        "            pass\n",
        "        time.sleep(0.6 * (i + 1))\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "ollama = OllamaCloud()\n",
        "\n",
        "# ----------------- DM campaign retrieval -----------------\n",
        "class CampaignKB:\n",
        "    def __init__(self, faiss_dir: Path):\n",
        "        self.faiss_dir = Path(faiss_dir)\n",
        "        self._vs = None\n",
        "        self._emb = None\n",
        "\n",
        "    def _embeddings(self):\n",
        "        if self._emb is None:\n",
        "            from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "            device = \"cuda\" if os.getenv(\"USE_CUDA\", \"0\") == \"1\" else \"cpu\"\n",
        "            self._emb = HuggingFaceEmbeddings(\n",
        "                model_name=os.getenv(\"SAFE_EMBED_MODEL\", \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"),\n",
        "                model_kwargs={\"device\": device},\n",
        "                encode_kwargs={\"normalize_embeddings\": True},\n",
        "            )\n",
        "        return self._emb\n",
        "\n",
        "    def _load(self):\n",
        "        if self._vs is not None:\n",
        "            return self._vs\n",
        "        if not (self.faiss_dir / \"index.faiss\").exists():\n",
        "            return None\n",
        "        from langchain_community.vectorstores import FAISS\n",
        "        self._vs = FAISS.load_local(str(self.faiss_dir), self._embeddings(), allow_dangerous_deserialization=True)\n",
        "        return self._vs\n",
        "\n",
        "    def retrieve(self, query: str, k: int = 6) -> str:\n",
        "        vs = self._load()\n",
        "        if vs is None:\n",
        "            return \"\"\n",
        "        docs = vs.similarity_search(query, k=k)\n",
        "        parts = []\n",
        "        for d in docs:\n",
        "            meta = d.metadata or {}\n",
        "            src = meta.get(\"source_file\") or \"unknown\"\n",
        "            page = meta.get(\"page\")\n",
        "            pfx = f\"[{src}{', ÑÑ‚Ñ€. ' + str(page) if page else ''}]\\n\"\n",
        "            txt = (d.page_content or \"\").strip()\n",
        "            if txt:\n",
        "                parts.append(pfx + txt)\n",
        "        return \"\\n\\n---\\n\\n\".join(parts).strip()\n",
        "\n",
        "\n",
        "campaign_kb = CampaignKB(FAISS_DIR)\n",
        "\n",
        "# ----------------- Player KB -----------------\n",
        "# player_kb is created in previous cell (PlayerKnowledgeBase)\n",
        "\n",
        "def player_retrieve(query: str, k: int = 15) -> tuple[bool, str]:\n",
        "    try:\n",
        "        return player_kb.search(query, top_k=k)  # type: ignore\n",
        "    except Exception:\n",
        "        return False, \"\"\n",
        "\n",
        "\n",
        "def player_answer(prompt_template: str, user_text: str) -> str:\n",
        "    found, ctx = player_retrieve(user_text, k=15)\n",
        "    warn = _player_warning(found)\n",
        "\n",
        "    prompt = prompt_template + \"\\n\\nÐ¤Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ñ‹ Ð¸Ð· Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹ Ð¸Ð³Ñ€Ð¾ÐºÐ°:\\n\" + (ctx if ctx else \"(Ð½ÐµÑ‚)\") + \"\\n\\nÐ—Ð°Ð¿Ñ€Ð¾Ñ Ð¸Ð³Ñ€Ð¾ÐºÐ°:\\n\" + (user_text or \"\")\n",
        "\n",
        "    msgs = [\n",
        "        {\"role\": \"system\", \"content\": \"Ð’Ñ‹Ð²Ð¾Ð´ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ñ€Ð¾ÑÑ‚Ñ‹Ð¼ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼. Ð‘ÐµÐ· Markdown/JSON/Ñ‚Ð°Ð±Ð»Ð¸Ñ†.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "    ]\n",
        "\n",
        "    out = ollama_with_retries(ollama, msgs, num_predict=OLLAMA_NUM_PREDICT, temperature=OLLAMA_TEMPERATURE, retries=2)\n",
        "    out = normalize_text(out)\n",
        "    if not out:\n",
        "        return \"Ð¡ÐµÑ€Ð²Ð¸Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾ Ð½Ðµ Ð²ÐµÑ€Ð½ÑƒÐ» Ñ‚ÐµÐºÑÑ‚. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ ÐµÑ‰Ñ‘ Ñ€Ð°Ð·.\"\n",
        "\n",
        "    return (warn + \"\\n\\n\" + out).strip() if warn else out\n",
        "\n",
        "\n",
        "# ----------------- TTS (Silero) -----------------\n",
        "class SileroTTS:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.sample_rate = 48000\n",
        "        self.speakers = {\"ÐœÑƒÐ¶ÑÐºÐ¾Ð¹\": \"aidar\", \"Ð–ÐµÐ½ÑÐºÐ¸Ð¹\": \"xenia\", VOICE_MALE: \"aidar\", VOICE_FEMALE: \"xenia\"}\n",
        "\n",
        "    def _init(self):\n",
        "        if self.model is not None:\n",
        "            return\n",
        "        import torch\n",
        "        self.model, _ = torch.hub.load(repo_or_dir=\"snakers4/silero-models\", model=\"silero_tts\", language=\"ru\", speaker=\"v5_ru\")\n",
        "        self.model.to(torch.device(\"cpu\"))\n",
        "\n",
        "    def synthesize(self, text: str, voice: str, out_dir: Path) -> Path:\n",
        "        import numpy as np\n",
        "        self._init()\n",
        "        speaker = self.speakers.get(voice, \"aidar\")\n",
        "        out_dir.mkdir(parents=True, exist_ok=True)\n",
        "        base = f\"tts_{speaker}_{int(time.time()*1000)}\"\n",
        "        wav = out_dir / f\"{base}.wav\"\n",
        "        audio = self.model.apply_tts(text=(text or \"\").strip(), speaker=speaker, sample_rate=self.sample_rate, put_accent=True, put_yo=True)\n",
        "        audio = np.asarray(audio)\n",
        "        try:\n",
        "            import soundfile as sf\n",
        "            sf.write(str(wav), audio, self.sample_rate)\n",
        "        except Exception:\n",
        "            from scipy.io.wavfile import write as w\n",
        "            max_abs = float(np.max(np.abs(audio))) or 1.0\n",
        "            w(str(wav), self.sample_rate, (audio / max_abs * 32767).astype(np.int16))\n",
        "        try:\n",
        "            from pydub import AudioSegment\n",
        "            mp3 = out_dir / f\"{base}.mp3\"\n",
        "            AudioSegment.from_wav(str(wav)).export(str(mp3), format=\"mp3\")\n",
        "            return mp3\n",
        "        except Exception:\n",
        "            return wav\n",
        "\n",
        "\n",
        "tts = SileroTTS()\n",
        "\n",
        "# ----------------- NPC replies -----------------\n",
        "NPC_DIALOG_SYSTEM = NPC_DIALOG_PROMPT\n",
        "\n",
        "\n",
        "def gen_npc_reply(user_prompt: str) -> str:\n",
        "    ctx = campaign_kb.retrieve(user_prompt, k=6)\n",
        "    payload = \"ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ ÐºÐ°Ð¼Ð¿Ð°Ð½Ð¸Ð¸:\\n\" + (ctx if ctx else \"(Ð½ÐµÑ‚)\") + \"\\n\\nÐ¡Ð¸Ñ‚ÑƒÐ°Ñ†Ð¸Ñ/Ñ€ÐµÐ¿Ð»Ð¸ÐºÐ° Ð¸Ð³Ñ€Ð¾ÐºÐ°:\\n\" + (user_prompt or \"\")\n",
        "    msgs = [{\"role\": \"system\", \"content\": NPC_DIALOG_SYSTEM}, {\"role\": \"user\", \"content\": payload}]\n",
        "    out = ollama_with_retries(ollama, msgs, num_predict=OLLAMA_NUM_PREDICT_REPLIES, temperature=OLLAMA_TEMPERATURE_REPLIES, retries=2)\n",
        "    out = normalize_text(out)\n",
        "    if not out or _looks_like_bad_reply(out):\n",
        "        msgs2 = [\n",
        "            {\"role\": \"system\", \"content\": \"ÐŸÐµÑ€ÐµÐ¿Ð¸ÑˆÐ¸ ÐºÐ°Ðº Ð¾Ð´Ð½Ñƒ ÑÐ²ÑÐ·Ð½ÑƒÑŽ Ñ€ÐµÐ¿Ð»Ð¸ÐºÑƒ NPC (1â€“3 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ), Ñ…Ð¾Ñ€Ð¾ÑˆÐ¸Ð¹ Ñ€ÑƒÑÑÐºÐ¸Ð¹, Ð±ÐµÐ· ÑÐ»ÐµÐ½Ð³Ð° Ð¸ Ð±ÐµÐ· ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ð¾Ð².\"},\n",
        "            {\"role\": \"user\", \"content\": payload + \"\\n\\nÐ§ÐµÑ€Ð½Ð¾Ð²Ð¸Ðº:\\n\" + (out or \"\")},\n",
        "        ]\n",
        "        out2 = normalize_text(ollama_with_retries(ollama, msgs2, num_predict=OLLAMA_NUM_PREDICT_REPLIES, temperature=0.1, retries=2))\n",
        "        if out2:\n",
        "            out = out2\n",
        "    return out or \"Ð¡ÐµÑ€Ð²Ð¸Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾ Ð½Ðµ Ð²ÐµÑ€Ð½ÑƒÐ» Ñ‚ÐµÐºÑÑ‚. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ ÐµÑ‰Ñ‘ Ñ€Ð°Ð·.\"\n",
        "\n",
        "\n",
        "# ----------------- Bot handlers -----------------\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    context.user_data.clear()\n",
        "    await safe_reply(update, WELCOME_TEXT, reply_markup=KB_MAIN)\n",
        "\n",
        "\n",
        "async def router(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    text = (update.message.text or \"\").strip()\n",
        "\n",
        "    # Global navigation\n",
        "    if text == \"Restart ðŸ”„\":\n",
        "        context.user_data.clear()\n",
        "        await safe_reply(update, \"ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½.\", reply_markup=KB_MAIN)\n",
        "        return\n",
        "    if text == \"â† Ð“Ð»Ð°Ð²Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ\":\n",
        "        context.user_data.clear()\n",
        "        await safe_reply(update, WELCOME_TEXT, reply_markup=KB_MAIN)\n",
        "        return\n",
        "\n",
        "    # Role selection (repeatable)\n",
        "    if text == \"Dungeon Master ðŸ§™â€â™‚ï¸\":\n",
        "        context.user_data[\"role\"] = \"dm\"\n",
        "        context.user_data[\"mode\"] = None\n",
        "        await safe_reply(update, \"ÐœÐµÐ½ÑŽ Ð¼Ð°ÑÑ‚ÐµÑ€Ð°:\", reply_markup=KB_DM)\n",
        "        return\n",
        "    if text == \"Player ðŸŽ²\":\n",
        "        context.user_data[\"role\"] = \"player\"\n",
        "        context.user_data[\"mode\"] = None\n",
        "        await safe_reply(update, \"ÐœÐµÐ½ÑŽ Ð¸Ð³Ñ€Ð¾ÐºÐ°:\", reply_markup=KB_PLAYER)\n",
        "        return\n",
        "\n",
        "    role = context.user_data.get(\"role\")\n",
        "    mode = context.user_data.get(\"mode\")\n",
        "\n",
        "    # Player menus\n",
        "    if role == \"player\":\n",
        "        if text == \"Ð’Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¿Ð¾ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°Ð¼\":\n",
        "            context.user_data[\"mode\"] = \"player_rules\"\n",
        "            await safe_reply(update, \"Ð—Ð°Ð´Ð°Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°Ð¼:\")\n",
        "            return\n",
        "        if text == \"ÐŸÐ¾Ð¼Ð¾Ñ‰ÑŒ Ð² ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ð¸Ð¸\":\n",
        "            context.user_data[\"mode\"] = \"player_situation\"\n",
        "            await safe_reply(update, \"ÐžÐ¿Ð¸ÑˆÐ¸ ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ð¸ÑŽ:\")\n",
        "            return\n",
        "\n",
        "        if mode == \"player_rules\":\n",
        "            await safe_reply(update, player_answer(PLAYER_RULES_PROMPT, text))\n",
        "            return\n",
        "        if mode == \"player_situation\":\n",
        "            await safe_reply(update, player_answer(PLAYER_SITUATION_PROMPT, text))\n",
        "            return\n",
        "\n",
        "        await safe_reply(update, \"ÐœÐµÐ½ÑŽ Ð¸Ð³Ñ€Ð¾ÐºÐ°:\", reply_markup=KB_PLAYER)\n",
        "        return\n",
        "\n",
        "    # DM menus\n",
        "    if role == \"dm\":\n",
        "        if text == \"Ð ÐµÐ¿Ð»Ð¸ÐºÐ¸\":\n",
        "            context.user_data[\"mode\"] = \"replies_menu\"\n",
        "            await safe_reply(update, \"Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚:\", reply_markup=KB_REPLIES)\n",
        "            return\n",
        "        if text == \"Ð¢ÐµÐºÑÑ‚\":\n",
        "            context.user_data[\"mode\"] = \"npc_text\"\n",
        "            await safe_reply(update, \"ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚ Ð´Ð»Ñ Ñ€ÐµÐ¿Ð»Ð¸ÐºÐ¸:\")\n",
        "            return\n",
        "        if text == \"ÐžÐ·Ð²ÑƒÑ‡ÐºÐ° + Ñ‚ÐµÐºÑÑ‚\":\n",
        "            context.user_data[\"mode\"] = \"npc_tts_voice\"\n",
        "            await safe_reply(update, \"Ð’Ñ‹Ð±ÐµÑ€Ð¸ Ð³Ð¾Ð»Ð¾Ñ NPC:\", reply_markup=KB_VOICE)\n",
        "            return\n",
        "        if text == \"ÐœÑƒÐ¶ÑÐºÐ¾Ð¹\" and mode == \"npc_tts_voice\":\n",
        "            context.user_data[\"tts_voice\"] = VOICE_MALE\n",
        "            context.user_data[\"mode\"] = \"npc_tts\"\n",
        "            await safe_reply(update, \"ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð´Ð»Ñ Ñ€ÐµÐ¿Ð»Ð¸ÐºÐ¸ NPC (Ð²ÐµÑ€Ð½Ñƒ Ñ‚ÐµÐºÑÑ‚ + Ð°ÑƒÐ´Ð¸Ð¾).\", reply_markup=KB_REPLIES)\n",
        "            return\n",
        "        if text == \"Ð–ÐµÐ½ÑÐºÐ¸Ð¹\" and mode == \"npc_tts_voice\":\n",
        "            context.user_data[\"tts_voice\"] = VOICE_FEMALE\n",
        "            context.user_data[\"mode\"] = \"npc_tts\"\n",
        "            await safe_reply(update, \"ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð´Ð»Ñ Ñ€ÐµÐ¿Ð»Ð¸ÐºÐ¸ NPC (Ð²ÐµÑ€Ð½Ñƒ Ñ‚ÐµÐºÑÑ‚ + Ð°ÑƒÐ´Ð¸Ð¾).\", reply_markup=KB_REPLIES)\n",
        "            return\n",
        "\n",
        "        mode = context.user_data.get(\"mode\")\n",
        "\n",
        "        if mode == \"npc_text\":\n",
        "            await safe_reply(update, gen_npc_reply(text))\n",
        "            return\n",
        "\n",
        "        if mode == \"npc_tts\":\n",
        "            reply = gen_npc_reply(text)\n",
        "            await safe_reply(update, reply)\n",
        "\n",
        "            voice = context.user_data.get(\"tts_voice\", VOICE_MALE)\n",
        "            out_dir = Path(\"artifacts/tts\")\n",
        "            loop = asyncio.get_running_loop()\n",
        "            try:\n",
        "                audio_path = await loop.run_in_executor(None, lambda: tts.synthesize(reply, voice, out_dir))\n",
        "                with open(audio_path, \"rb\") as f:\n",
        "                    await update.message.reply_audio(audio=f, filename=audio_path.name)\n",
        "            except Exception as e:\n",
        "                logger.exception(\"TTS error\")\n",
        "                await safe_reply(update, f\"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ð·Ð²ÑƒÑ‡Ð¸Ñ‚ÑŒ: {e}\")\n",
        "            return\n",
        "\n",
        "        if text == \"â† ÐÐ°Ð·Ð°Ð´ (DM)\":\n",
        "            context.user_data[\"mode\"] = None\n",
        "            await safe_reply(update, \"ÐœÐµÐ½ÑŽ DM:\", reply_markup=KB_DM)\n",
        "            return\n",
        "\n",
        "        if text == \"Ð¥Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ Ð·Ð½Ð°Ð½Ð¸Ð¹\":\n",
        "            context.user_data[\"mode\"] = \"dm_knowledge\"\n",
        "            await safe_reply(update, \"Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð¿Ð¾ ÐºÐ°Ð¼Ð¿Ð°Ð½Ð¸Ð¸:\")\n",
        "            return\n",
        "\n",
        "        if mode == \"dm_knowledge\":\n",
        "            ctx = campaign_kb.retrieve(text, k=6)\n",
        "            if not ctx:\n",
        "                await safe_reply(update, \"ÐÐ¸Ñ‡ÐµÐ³Ð¾ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð² Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ.\")\n",
        "                return\n",
        "            msgs = [\n",
        "                {\"role\": \"system\", \"content\": \"ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ð¾ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð½Ð¾Ð¼Ñƒ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ. ÐŸÑ€Ð¾ÑÑ‚Ñ‹Ð¼ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼.\"},\n",
        "                {\"role\": \"user\", \"content\": ctx + \"\\n\\nÐ’Ð¾Ð¿Ñ€Ð¾Ñ: \" + text},\n",
        "            ]\n",
        "            out = normalize_text(ollama_with_retries(ollama, msgs, num_predict=OLLAMA_NUM_PREDICT, temperature=OLLAMA_TEMPERATURE, retries=2))\n",
        "            await safe_reply(update, out or \"Ð¡ÐµÑ€Ð²Ð¸Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾ Ð½Ðµ Ð²ÐµÑ€Ð½ÑƒÐ» Ñ‚ÐµÐºÑÑ‚. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ ÐµÑ‰Ñ‘ Ñ€Ð°Ð·.\")\n",
        "            return\n",
        "\n",
        "        await safe_reply(update, \"ÐœÐµÐ½ÑŽ DM:\", reply_markup=KB_DM)\n",
        "        return\n",
        "\n",
        "    # No role chosen yet\n",
        "    await safe_reply(update, \"Ð’Ñ‹Ð±ÐµÑ€Ð¸ Ñ€Ð¾Ð»ÑŒ:\", reply_markup=KB_MAIN)\n",
        "\n",
        "\n",
        "def main():\n",
        "    if not TG_BOT_TOKEN:\n",
        "        raise RuntimeError(\"TG_BOT_TOKEN Ð½Ðµ Ð·Ð°Ð´Ð°Ð½\")\n",
        "\n",
        "    app = ApplicationBuilder().token(TG_BOT_TOKEN).build()\n",
        "    app.add_handler(CommandHandler(\"start\", start))\n",
        "    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, router))\n",
        "\n",
        "    logger.info(\"Bot started\")\n",
        "    app.run_polling(close_loop=False)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
