{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxONqFfTgr4_",
        "outputId": "2f92a9d1-3975-4b99-9628-bab5a03c656a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install -q nest_asyncio\n",
        "!pip install -q -U python-telegram-bot\n",
        "!pip install -q sentence-transformers pypdf requests pdfminer.six psutil pymupdf\n",
        "!pip install -q langchain-community langchain-text-splitters faiss-cpu\n",
        "!pip install -q hf_xet omegaconf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9N6p2KwNgNAe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TG_BOT_TOKEN\"] = \"\"\n",
        "os.environ[\"OLLAMA_API_KEY\"] = \"\"  \n",
        "os.environ[\"OLLAMA_API_URL\"] = \"https://ollama.com/api/chat\"\n",
        "os.environ[\"OLLAMA_MODEL\"] = \"gpt-oss:20b-cloud\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PROMPTS / STYLE (–∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –±–æ—Ç–æ–º –Ω–∏–∂–µ)\n",
        "\n",
        "TELEGRAM_STYLE_SYSTEM = (\n",
        "    \"–û—Ç–≤–µ—á–∞–π –¥–ª—è —á–∞—Ç–∞ Telegram. –í—ã–≤–æ–¥ —Ç–æ–ª—å–∫–æ –ø—Ä–æ—Å—Ç—ã–º —Ç–µ–∫—Å—Ç–æ–º. \"\n",
        "    \"–ó–∞–ø—Ä–µ—â–µ–Ω–æ: —Å—Ö–µ–º—ã/ASCII-–∞—Ä—Ç, —Ç–∞–±–ª–∏—Ü—ã, —Å–ø–∏—Å–∫–∏ —Å –º–∞—Ä–∫–µ—Ä–∞–º–∏, Markdown (**, #, ```), JSON/XML/YAML, –∫–æ–¥. \"\n",
        "    \"–ü–∏—à–∏ –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É: 6‚Äì10 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –±–µ–∑ –ª–∏—à–Ω–µ–π –≤–æ–¥—ã. \"\n",
        "    \"–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –ø—Ä—è–º–æ —Å–∫–∞–∂–∏, —á–µ–≥–æ –Ω–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ, –∏ —á—Ç–æ –Ω—É–∂–Ω–æ —É—Ç–æ—á–Ω–∏—Ç—å.\"\n",
        ")\n",
        "\n",
        "PC_SHEET_PROMPT = \"\"\"–¢—ã ‚Äî –º–∞—Å—Ç–µ—Ä –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π Dungeons & Dragons 5e. –ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å—Ñ–æ—Ä–º–∏—Ä—É–π –ø–æ–ª–Ω–æ–µ, –∂–∏–≤–æ–µ –∏ —É–¥–æ–±–æ—á–∏—Ç–∞–µ–º–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞, –æ—Ä–∏–µ–Ω—Ç–∏—Ä—É—è—Å—å –Ω–∞ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –ª–∏—Å—Ç –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ (character sheet).\n",
        "\n",
        "–í—ã–≤–æ–¥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ç–æ–ª—å–∫–æ –≤ –≤–∏–¥–µ –ø—Ä–æ—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞, –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, —Ç–∞–±–ª–∏—Ü, —Å–ø–∏—Å–∫–æ–≤ –∏–ª–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π. –ö–∞–∂–¥–∞—è —Å–µ–∫—Ü–∏—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞, –∑–∞ –∫–æ—Ç–æ—Ä—ã–º —Å–ª–µ–¥—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ. –°–æ–±–ª—é–¥–∞–π —Å—Ç—Ä–æ–≥–æ —Å–ª–µ–¥—É—é—â–∏–π –ø–æ—Ä—è–¥–æ–∫:\n",
        "\n",
        "–ò–º—è: [–ø–æ–ª–Ω–æ–µ –∏–º—è]\n",
        "–†–∞—Å–∞: [—Ä–∞—Å–∞ –∏ –ø–æ–¥—Ä–∞—Å–∞, –µ—Å–ª–∏ –µ—Å—Ç—å]\n",
        "–ö–ª–∞—Å—Å: [–∫–ª–∞—Å—Å, –∞—Ä—Ö–µ—Ç–∏–ø/–ø–æ–¥–∫–ª–∞—Å—Å, —É—Ä–æ–≤–µ–Ω—å]\n",
        "–ü—Ä–µ–¥—ã—Å—Ç–æ—Ä–∏—è: [–ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä: ¬´–Ω–∞—ë–º–Ω–∏–∫¬ª, ¬´—É—á—ë–Ω—ã–π¬ª, ¬´–∏–∑–≥–Ω–∞–Ω–Ω–∏–∫¬ª]\n",
        "–ú–∏—Ä–æ–≤–æ–∑–∑—Ä–µ–Ω–∏–µ: [–Ω–∞–ø—Ä–∏–º–µ—Ä: ¬´–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ-–¥–æ–±—Ä—ã–π¬ª]\n",
        "\n",
        "–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:\n",
        "–°–∏–ª–∞ [—á–∏—Å–ª–æ] (+–º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä)\n",
        "–õ–æ–≤–∫–æ—Å—Ç—å [—á–∏—Å–ª–æ] (+–º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä)\n",
        "–¢–µ–ª–æ—Å–ª–æ–∂–µ–Ω–∏–µ [—á–∏—Å–ª–æ] (+–º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä)\n",
        "–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç [—á–∏—Å–ª–æ] (+–º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä)\n",
        "–ú—É–¥—Ä–æ—Å—Ç—å [—á–∏—Å–ª–æ] (+–º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä)\n",
        "–•–∞—Ä–∏–∑–º–∞ [—á–∏—Å–ª–æ] (+–º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä)\n",
        "\n",
        "–ö–ª–∞—Å—Å–æ–≤—ã–µ —Å–ø–∞—Å–±—Ä–æ—Å–∫–∏: [–Ω–∞–ø—Ä–∏–º–µ—Ä: ¬´–°–∏–ª–∞ +5, –¢–µ–ª–æ—Å–ª–æ–∂–µ–Ω–∏–µ +4¬ª]\n",
        "–ë—Ä–æ–Ω—è: [–∫–ª–∞—Å—Å –±—Ä–æ–Ω–∏, —Ç–∏–ø –±—Ä–æ–Ω–∏]\n",
        "–ò–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞: [+–º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä]\n",
        "–°–∫–æ—Ä–æ—Å—Ç—å: [–≤ —Ñ—É—Ç–∞—Ö, –Ω–∞–ø—Ä–∏–º–µ—Ä: ¬´30 —Ñ—Ç¬ª]\n",
        "–ú–∞–∫—Å–∏–º—É–º —Ö–∏—Ç–æ–≤: [—á–∏—Å–ª–æ]\n",
        "–¢–µ–∫—É—â–∏–µ —Ö–∏—Ç—ã: [—á–∏—Å–ª–æ]\n",
        "–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ö–∏—Ç—ã: [—á–∏—Å–ª–æ –∏–ª–∏ ¬´–Ω–µ—Ç¬ª]\n",
        "\n",
        "–ù–∞–≤—ã–∫–∏: [–ø–µ—Ä–µ—á–∏—Å–ª–∏ —Ç–æ–ª—å–∫–æ —Ç–µ, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂ –∫–æ–º–ø–µ—Ç–µ–Ω—Ç–µ–Ω, —Å –±–æ–Ω—É—Å–∞–º–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä: ¬´–í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å +6, –ó–∞–ø—É–≥–∏–≤–∞–Ω–∏–µ +5, –ê–∫—Ä–æ–±–∞—Ç–∏–∫–∞ +4¬ª]\n",
        "\n",
        "–Ø–∑—ã–∫–∏ –∏ –≤–ª–∞–¥–µ–Ω–∏—è: [—è–∑—ã–∫–∏, –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, –æ—Ä—É–∂–∏–µ, –±—Ä–æ–Ω—è ‚Äî –∫—Ä–∞—Ç–∫–æ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é]\n",
        "\n",
        "–ß–µ—Ä—Ç—ã —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞: [1‚Äì2 —è—Ä–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –ø–æ–≤–µ–¥–µ–Ω–∏—è]\n",
        "–ò–¥–µ–∞–ª—ã: [–≤–æ —á—Ç–æ –≤–µ—Ä–∏—Ç]\n",
        "–ü—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç–∏: [–∫—Ç–æ –∏–ª–∏ —á—Ç–æ –µ–º—É –¥–æ—Ä–æ–≥–æ]\n",
        "–°–ª–∞–±–æ—Å—Ç–∏: [—Å—Ç—Ä–∞—Ö–∏, –ø–æ—Ä–æ–∫–∏, –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã]\n",
        "\n",
        "–í–Ω–µ—à–Ω–æ—Å—Ç—å: [—Ä–æ—Å—Ç, –≤–µ—Å, —Ü–≤–µ—Ç –≥–ª–∞–∑/–≤–æ–ª–æ—Å/–∫–æ–∂–∏, –æ–¥–µ–∂–¥–∞, —à—Ä–∞–º—ã, —É–∫—Ä–∞—à–µ–Ω–∏—è ‚Äî –≤—Å—ë, —á—Ç–æ –≤–∏–¥–Ω–æ —Å—Ä–∞–∑—É]\n",
        "\n",
        "–°–æ—é–∑–Ω–∏–∫–∏ –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏: [–∫—Ç–æ –Ω–∞ –µ–≥–æ —Å—Ç–æ—Ä–æ–Ω–µ, —á–ª–µ–Ω—Å—Ç–≤–æ –≤ –≥—Ä—É–ø–ø–∞—Ö]\n",
        "\n",
        "–¶–µ–ª—å: [–ø–æ—á–µ–º—É –æ–Ω –ø—É—Ç–µ—à–µ—Å—Ç–≤—É–µ—Ç, —á—Ç–æ –∏—â–µ—Ç –∏–ª–∏ –∑–∞—â–∏—â–∞–µ—Ç]\n",
        "\n",
        "–û—Å–æ–±—ã–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∏ —á–µ—Ä—Ç—ã —Ä–∞—Å—ã/–∫–ª–∞—Å—Å–∞: [–∫—Ä–∞—Ç–∫–æ ‚Äî —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è –∏–≥—Ä—ã –∏ –æ—Ç—ã–≥—Ä—ã—à–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä: ¬´–¢–µ–º–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ 60 —Ñ—Ç¬ª, ¬´–ë–æ–µ–≤–æ–π —Å—Ç–∏–ª—å: –ó–∞—â–∏—Ç–∞¬ª, ¬´–£–¥–∞—á–∞ –ø–æ–ª—É—Ä–æ—Å–ª–∏–∫–∞¬ª]\n",
        "\n",
        "–ù–µ –¥–æ–±–∞–≤–ª—è–π –ø–æ—è—Å–Ω–µ–Ω–∏–π, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏–ª–∏ –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –∂–∏—Ä–Ω—ã–π —à—Ä–∏—Ñ—Ç, –∫—É—Ä—Å–∏–≤, –∑–≤—ë–∑–¥–æ—á–∫–∏, —Ç–∏—Ä–µ –∫–∞–∫ –º–∞—Ä–∫–µ—Ä—ã, JSON, XML –∏–ª–∏ –ª—é–±—ã–µ –¥—Ä—É–≥–∏–µ —Ñ–æ—Ä–º–∞—Ç—ã. –¢–æ–ª—å–∫–æ —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç ‚Äî –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞.\"\"\"\n",
        "\n",
        "NPC_PROMPT = \"\"\"–°–æ–∑–¥–∞–π –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–µ–∏–≥—Ä–æ–≤–æ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ (NPC) –¥–ª—è Dungeons & Dragons 5e. –í—ã–≤–µ–¥–∏ —Ç–æ–ª—å–∫–æ –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç, –±–µ–∑ —Ç–∞–±–ª–∏—Ü, —Å–ø–∏—Å–∫–æ–≤ –∏–ª–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è. –°–æ–±–ª—é–¥–∞–π —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É ‚Äî –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞:\n",
        "\n",
        "–ò–º—è:\n",
        "–†–∞—Å–∞:\n",
        "–í–æ–∑—Ä–∞—Å—Ç:\n",
        "–†–æ–¥ –∑–∞–Ω—è—Ç–∏–π:\n",
        "–ú–∏—Ä–æ–≤–æ–∑–∑—Ä–µ–Ω–∏–µ:\n",
        "–í–Ω–µ—à–Ω–æ—Å—Ç—å:\n",
        "–•–∞—Ä–∞–∫—Ç–µ—Ä:\n",
        "–¶–µ–ª—å –∏–ª–∏ –º–æ—Ç–∏–≤–∞—Ü–∏—è:\n",
        "–û—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ –∏–≥—Ä–æ–∫–∞–º:\n",
        "–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:\n",
        "–°–µ–∫—Ä–µ—Ç:\n",
        "\n",
        "–ü–∏—à–∏ –∫—Ä–∞—Ç–∫–æ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ. –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ ‚Äî —ç—Ç–æ —Ç–æ, —á—Ç–æ –¥–µ–ª–∞–µ—Ç NPC –∑–∞–ø–æ–º–∏–Ω–∞—é—â–∏–º—Å—è (–ø—Ä–∏–≤—ã—á–∫–∞, –º–∞–Ω–µ—Ä–∞ —Ä–µ—á–∏, –ø—Ä–µ–¥–º–µ—Ç –æ–¥–µ–∂–¥—ã –∏ —Ç.–ø.). –°–µ–∫—Ä–µ—Ç ‚Äî –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–º (¬´–±–æ–∏—Ç—Å—è –∫—Ä—ã—Å¬ª) –∏–ª–∏ –≤–∞–∂–Ω—ã–º (¬´–∫–æ–Ω—Ç—Ä–∞–±–∞–Ω–¥–∏—Å—Ç¬ª), –Ω–æ –µ—Å–ª–∏ NPC –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –æ–±—ã–¥–µ–Ω–Ω—ã–π ‚Äî —Å–µ–∫—Ä–µ—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º –∏–ª–∏ –±—ã—Ç–æ–≤—ã–º. –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π —ç–ø–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —É–º–µ—Å—Ç–Ω—ã. –ì–ª–∞–≤–Ω–æ–µ ‚Äî —á—Ç–æ–±—ã –±—ã–ª–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –∂–∏–≤–æ–≥–æ –æ—Ç—ã–≥—Ä—ã—à–∞ –∑–∞ 1‚Äì2 –º–∏–Ω—É—Ç—ã.\"\"\"\n",
        "\n",
        "NPC_DIALOG_PROMPT = \"\"\"–¢—ã ‚Äî NPC –≤ —Ñ—ç–Ω—Ç–µ–∑–∏–π–Ω–æ–π –∫–∞–º–ø–∞–Ω–∏–∏ Dungeons & Dragons 5e.\n",
        "\n",
        "–¢–µ–±–µ –±—É–¥–µ—Ç –¥–∞–Ω–æ:\n",
        "1) –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–µ—Ç—Ç–∏–Ω–≥–∞/–∫–∞–º–ø–∞–Ω–∏–∏ (–µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω), –µ—Å–ª–∏ –Ω–µ—Ç –µ–≥–æ, –∏—Å–ø–æ–ª—å–∑—É–π –§–∞—ç—Ä—É–Ω –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π —Å–µ—Ç—Ç–∏–Ω–≥\n",
        "2) –†–µ–ø–ª–∏–∫–∞/—Å–∏—Ç—É–∞—Ü–∏—è, –Ω–∞ –∫–æ—Ç–æ—Ä—É—é –Ω—É–∂–Ω–æ —Å–∏–º–º—É–ª–∏—Ä–æ–≤–∞—Ç—å, —á–∞—â–µ –≤—Å–µ–≥–æ —ç—Ç–æ —Ä–µ–ø–ª–∏–∫–∞ –æ–±—Ä–∞—â–µ–Ω–∞—è –∫ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞–º –∏–≥—Ä–æ–∫–æ–≤\n",
        "\n",
        "–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å—Ç–∏–ª—é –∏ —Å–µ—Ç—Ç–∏–Ω–≥—É:\n",
        "–ù–µ –±—É–¥—å –∏–∑–ª–∏—à–Ω–µ —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–º, –≤–µ–¥–∏ —Å–µ–±—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ\n",
        "–ü–∏—à–∏ –ø–æ-—Ä—É—Å—Å–∫–∏, –≥—Ä–∞–º–æ—Ç–Ω–æ –∏ —Å–≤—è–∑–Ω–æ, –∫–∞–∫ –∂–∏–≤–æ–π –ø–µ—Ä—Å–æ–Ω–∞–∂.\n",
        "–û–¥–Ω–∞ —Ü–µ–ª—å: –≤—ã–¥–∞—Ç—å –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω—É—é —Ä–µ–ø–ª–∏–∫—É NPC.\n",
        "–ü–∏—à–∏ –∫–∞–∫ –ø–µ—Ä—Å–æ–Ω–∞–∂ –≤ —Å—Ä–µ–¥–Ω–µ–≤–µ–∫–æ–≤–æ–º/—Ñ—ç–Ω—Ç–µ–∑–∏–π–Ω–æ–º –º–∏—Ä–µ.\n",
        "–ò—Å–ø–æ–ª—å–∑—É–π —Ç–µ—Ä–º–∏–Ω—ã D&D –∏–ª–∏ –±–ª–∏–∑–∫–∏–µ –∫ —Å—Ä–µ–¥–Ω–µ–≤–µ–∫–æ–≤—å—é (—Ç—Ä–∞–∫—Ç–∏—Ä, —Å—Ç—Ä–∞–∂–∞, –≥–∏–ª—å–¥–∏—è, —Ö—Ä–∞–º, –º–∞–≥, –∂—Ä–µ—Ü, —Å–≤–∏—Ç–æ–∫, –∞—Ä–±–∞–ª–µ—Ç –∏ —Ç.–ø.).\n",
        "–ó–∞–ø—Ä–µ—â–µ–Ω—ã —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏: –∫–æ–º–ø—å—é—Ç–µ—Ä—ã, –∏–Ω—Ç–µ—Ä–Ω–µ—Ç, —Å–º–∞—Ä—Ç—Ñ–æ–Ω—ã, –ª–∞–∑–µ—Ä—ã, —Ä–∞–∫–µ—Ç—ã, —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å—Ç–≤–æ –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–º —Å–º—ã—Å–ª–µ, –æ–≥–Ω–µ—Å—Ç—Ä–µ–ª –∫–∞–∫ –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–º –º–∏—Ä–µ.\n",
        "–ó–∞–ø—Ä–µ—â—ë–Ω —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å–ª–µ–Ω–≥ –∏ –º–µ–º—ã.\n",
        "–ï—Å–ª–∏ –∏–≥—Ä–æ–∫ –≥–æ–≤–æ—Ä–∏—Ç —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏, –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π –∏—Ö ¬´–≤–Ω—É—Ç—Ä–∏—Å–µ—Ç—Ç–∏–Ω–≥–æ–≤–æ¬ª.\n",
        "\n",
        "–í—ã–≤–æ–¥:\n",
        "–û–¥–Ω–∞ —Ä–µ–ø–ª–∏–∫–∞ (3‚Äì5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –æ—Ç –∏–º–µ–Ω–∏ NPC/–ü–µ—Ä—Å–æ–Ω–∞–∂–∞. –ù–µ –∑–∞–±—ã–≤–∞–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ–∂–¥–æ–º–µ—Ç–∏—è, –≥–æ–≤–æ—Ä–∏ –∫–∞–ª–æ—Ä–∏—Ç–Ω–æ. –ë–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π –∏ –±–µ–∑ —Å–ª—É–∂–µ–±–Ω—ã—Ö –ø–æ–º–µ—Ç–æ–∫.\"\"\"\n",
        "\n",
        "COMBAT_PROMPT = \"\"\"–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π –ú–∞—Å—Ç–µ—Ä –ü–æ–¥–∑–µ–º–µ–ª–∏–π, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏ –∑–∞—Ö–≤–∞—Ç—ã–≤–∞—é—â–∏—Ö –±–æ—ë–≤ –¥–ª—è D&D 5e. –ù–∞ –æ—Å–Ω–æ–≤–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (—É—Ä–æ–≤–Ω–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π, –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏ –∫–ª–∞—Å—Å—ã) —Å–æ–∑–¥–∞–π –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –±–æ–µ–≤–æ–π –≤—Å—Ç—Ä–µ—á–∏.\n",
        "\n",
        "–í—ã–≤–µ–¥–∏ –¢–û–õ–¨–ö–û –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç –≤ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ ‚Äî –∫–∞–∂–¥–∞—è —Å–µ–∫—Ü–∏—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞, –∑–∞ –∫–æ—Ç–æ—Ä—ã–º —Å–ª–µ–¥—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ. –ù–∏–∫–∞–∫–∏—Ö —Ç–∞–±–ª–∏—Ü, JSON, markdown –∏–ª–∏ –ª–∏—à–Ω–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤:\n",
        "\n",
        "–°–ª–æ–∂–Ω–æ—Å—Ç—å –≤—Å—Ç—Ä–µ—á–∏: [—É—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏: –ª—ë–≥–∫–∞—è/—Å—Ä–µ–¥–Ω—è—è/—Å–ª–æ–∂–Ω–∞—è/—Å–º–µ—Ä—Ç–µ–ª—å–Ω–∞—è]\n",
        "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–±–µ–¥—ã –≥—Ä—É–ø–ø—ã: [–ø—Ä–∏–º–µ—Ä–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç –∏ –∫—Ä–∞—Ç–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ]\n",
        "\n",
        "–û–ü–ò–°–ê–ù–ò–ï –í–°–¢–†–ï–ß–ò:\n",
        "[–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ—Ç–∏–≤–Ω–∏–∫–æ–≤: –∫—Ç–æ –æ–Ω–∏, –ø–æ—á–µ–º—É –∞—Ç–∞–∫—É—é—Ç, –∏—Ö —Ç–∞–∫—Ç–∏–∫–∞ –≤ 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö]\n",
        "\n",
        "–ü–†–û–¢–ò–í–ù–ò–ö–ò:\n",
        "[–î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –ø—Ä–æ—Ç–∏–≤–Ω–∏–∫–∞ —É–∫–∞–∂–∏:]\n",
        "\n",
        "–ù–∞–∑–≤–∞–Ω–∏–µ: [—Ä–∞—Å–∞/–∫–ª–∞—Å—Å]\n",
        "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: [—á–∏—Å–ª–æ]\n",
        "–ö–ª–∞—Å—Å –¥–æ—Å–ø–µ—Ö–∞: [—á–∏—Å–ª–æ]\n",
        "–•–∏—Ç—ã: [—á–∏—Å–ª–æ + –∫–æ—Å—Ç–∏ —Ö–∏—Ç–æ–≤, –Ω–∞–ø—Ä–∏–º–µ—Ä: \"22 (3–∫8+9)\"]\n",
        "–°–∫–æ—Ä–æ—Å—Ç—å: [—á–∏—Å–ª–æ —Ñ—É—Ç–æ–≤]\n",
        "–ö–ª—é—á–µ–≤—ã–µ –∞—Ç–∞–∫–∏:\n",
        "[–ù–∞–∑–≤–∞–Ω–∏–µ –∞—Ç–∞–∫–∏]: [+–∫_–∞—Ç–∞–∫–µ] –∫ –∞—Ç–∞–∫–µ, [—É—Ä–æ–Ω+–∫–æ—Å—Ç–∏], —Ç–∏–ø —É—Ä–æ–Ω–∞\n",
        "–û—Å–æ–±—ã–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏: [–Ω–∞–∑–≤–∞–Ω–∏—è –∏ –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ]\n",
        "–¢–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏—ë–º—ã: [2-3 –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã—Ö —Ö–æ–¥–∞ –≤ –±–æ—é, –Ω–µ–æ—á–µ–≤–∏–¥–Ω—ã–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π]\n",
        "\n",
        "–û–ö–†–£–ñ–ï–ù–ò–ï:\n",
        "[–û–ø–∏—Å–∞–Ω–∏–µ –ª–æ–∫–∞—Ü–∏–∏: –ø—Ä–µ–ø—è—Ç—Å—Ç–≤–∏—è, —É–∫—Ä—ã—Ç–∏—è, –ª–æ–≤—É—à–∫–∏, –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É—é—â–∏–µ –æ–±—ä–µ–∫—Ç—ã]\n",
        "\n",
        "–ù–ê–ì–†–ê–î–´:\n",
        "–û–ø—ã—Ç: [–æ–±—â–µ–µ —á–∏—Å–ª–æ –æ–ø—ã—Ç–∞ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –º–µ–∂–¥—É –∏–≥—Ä–æ–∫–∞–º–∏]\n",
        "–°–æ–∫—Ä–æ–≤–∏—â–∞: [–ø—Ä–µ–¥–º–µ—Ç—ã, –∑–æ–ª–æ—Ç–æ, –º–∞–≥–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–¥–º–µ—Ç—ã]\n",
        "–û—Å–æ–±—ã–µ –Ω–∞–≥—Ä–∞–¥—ã: [–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, —Å–æ—é–∑–Ω–∏–∫–∏, –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö –∫–≤–µ—Å—Ç–æ–≤]\n",
        "\n",
        "–°–û–í–ï–¢–´ –ú–ê–°–¢–ï–†–£:\n",
        "\n",
        "–ë–∞–ª–∞–Ω—Å: [—á—Ç–æ –¥–æ–±–∞–≤–∏—Ç—å/—É–±—Ä–∞—Ç—å, –µ—Å–ª–∏ –±–æ–π —Å–ª–∏—à–∫–æ–º –ª—ë–≥–∫–∏–π –∏–ª–∏ —Å–ª–æ–∂–Ω—ã–π]\n",
        "–ê—Ç–º–æ—Å—Ñ–µ—Ä–∞: [–∫–∞–∫ –æ–ø–∏—Å–∞—Ç—å –Ω–∞—á–∞–ª–æ –±–æ—è –∏ –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã]\n",
        "–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã: [–≤–∞—Ä–∏–∞–Ω—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –±–æ—è –ø–æ–º–∏–º–æ —É–±–∏–π—Å—Ç–≤–∞ –≤—Å–µ—Ö –ø—Ä–æ—Ç–∏–≤–Ω–∏–∫–æ–≤]\n",
        "–í–∞–∂–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏: [–∫–∞–∫–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–≤—ã–∫–æ–≤ –∏–∑–º–µ–Ω—è—Ç —Ö–æ–¥ –±–æ—è]\n",
        "\n",
        "–î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û:\n",
        "[–ü–æ–ª–µ–∑–Ω—ã–µ –ø—Ä–∏–º–µ—á–∞–Ω–∏—è: –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è –±–æ—è, —Å–≤—è–∑—å —Å —Å—é–∂–µ—Ç–æ–º, —Ä–µ–∞–∫—Ü–∏—è NPC –ø–æ—Å–ª–µ –±–æ—è]\"\"\"\n",
        "\n",
        "PLAYER_RULES_PROMPT = \"\"\"–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ –∏–≥—Ä–æ–∫–∞ D&D 5e. –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º –∏ –º–µ—Ö–∞–Ω–∏–∫–∞–º.\n",
        "\n",
        "–¢–µ–±–µ –±—É–¥–µ—Ç –¥–∞–Ω–æ:\n",
        "1) –í–æ–ø—Ä–æ—Å –∏–≥—Ä–æ–∫–∞\n",
        "2) (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏–≥—Ä–æ–∫–∞\n",
        "\n",
        "–ï—Å–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –µ—Å—Ç—å ‚Äî –æ–ø–∏—Ä–∞–π—Å—è –Ω–∞ –Ω–∏—Ö. –ï—Å–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ—Ç ‚Äî –æ—Ç–≤–µ—Ç—å –ø–æ –æ–±—â–∏–º –∑–Ω–∞–Ω–∏—è–º D&D 5e.\n",
        "\n",
        "–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:\n",
        "–ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∫–∞–ø—Å–æ–º.\n",
        "–ù–µ –ø–∏—à–∏ —Å–ª—É–∂–µ–±–Ω—ã–µ —Ñ–ª–∞–≥–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, \"found\", \"—Ñ–ª–∞–≥\", \"–∫–æ–Ω—Ç–µ–∫—Å—Ç\", \"–±–∞–∑–∞: –¥–∞/–Ω–µ—Ç\").\n",
        "–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –¥–µ—Ç–∞–ª–∏ –∫–∞–º–ø–∞–Ω–∏–∏.\n",
        "\n",
        "–§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞:\n",
        "–°–Ω–∞—á–∞–ª–∞ –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç (1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).\n",
        "–ü–æ—Ç–æ–º –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞.\n",
        "–ü–æ—Ç–æ–º –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ (6‚Äì10 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π).\n",
        "–ü–æ—Ç–æ–º (–µ—Å–ª–∏ —É–º–µ—Å—Ç–Ω–æ) –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –∏ —Å—Ç—Ä–æ–∫–∞ \"–ü—Ä–∏–º–µ—Ä –≤ –∏–≥—Ä–µ: ...\".\n",
        "\"\"\"\n",
        "\n",
        "PLAYER_SITUATION_PROMPT = \"\"\"–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ –∏–≥—Ä–æ–∫–∞ D&D 5e. –ü–æ–º–æ–≥–∏ —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è –≤ —Å–∏—Ç—É–∞—Ü–∏–∏ –∑–∞ —Å—Ç–æ–ª–æ–º.\n",
        "\n",
        "–¢–µ–±–µ –±—É–¥–µ—Ç –¥–∞–Ω–æ:\n",
        "1) –û–ø–∏—Å–∞–Ω–∏–µ —Å–∏—Ç—É–∞—Ü–∏–∏ –∏–≥—Ä–æ–∫–æ–º\n",
        "2) (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏–≥—Ä–æ–∫–∞\n",
        "\n",
        "–ï—Å–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –µ—Å—Ç—å ‚Äî –æ–ø–∏—Ä–∞–π—Å—è –Ω–∞ –Ω–∏—Ö. –ï—Å–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ—Ç ‚Äî –ø–æ–º–æ–≥–∏ –ø–æ –æ–±—â–∏–º –∑–Ω–∞–Ω–∏—è–º D&D 5e.\n",
        "\n",
        "–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:\n",
        "–ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∫–∞–ø—Å–æ–º.\n",
        "–ù–µ –ø–∏—à–∏ —Å–ª—É–∂–µ–±–Ω—ã–µ —Ñ–ª–∞–≥–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, \"found\", \"—Ñ–ª–∞–≥\", \"–∫–æ–Ω—Ç–µ–∫—Å—Ç\", \"–±–∞–∑–∞: –¥–∞/–Ω–µ—Ç\").\n",
        "–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –¥–µ—Ç–∞–ª–∏ –∫–∞–º–ø–∞–Ω–∏–∏.\n",
        "\n",
        "–§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞:\n",
        "–°–Ω–∞—á–∞–ª–∞ –∫–æ—Ä–æ—Ç–∫–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è (1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).\n",
        "–ü–æ—Ç–æ–º –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞.\n",
        "–ü–æ—Ç–æ–º —Ä–∞–∑–±–æ—Ä –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Å–æ–≤–µ—Ç (8‚Äì12 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π).\n",
        "–ü–æ—Ç–æ–º (–µ—Å–ª–∏ —É–º–µ—Å—Ç–Ω–æ) –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –∏ —Å—Ç—Ä–æ–∫–∞ \"–ü—Ä–∏–º–µ—Ä –≤ –∏–≥—Ä–µ: ...\".\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PLAYER FAISS RAG (–æ—Ç–¥–µ–ª—å–Ω–∞—è –±–∞–∑–∞, –±–µ–∑ –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞–Ω–Ω—ã–º DM)\n",
        "import os\n",
        "import re\n",
        "import gc\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import Optional, Tuple, List, Iterator\n",
        "\n",
        "logger = logging.getLogger(\"rag-dnd-bot-faiss\")\n",
        "\n",
        "PLAYER_DATASET_DIR = Path(os.getenv(\"PLAYER_DATASET_DIR\", \"Dataset/Main\"))\n",
        "PLAYER_FAISS_DIR = Path(os.getenv(\"PLAYER_FAISS_DIR\", \"artifacts/faiss_player_knowledge\"))\n",
        "PLAYER_FALLBACK_EMBED_MODEL = os.getenv(\"PLAYER_FALLBACK_EMBED_MODEL\", \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
        "PLAYER_EMBED_MODEL = os.getenv(\"PLAYER_EMBED_MODEL\", PLAYER_FALLBACK_EMBED_MODEL)\n",
        "PLAYER_CHUNK_SIZE = int(os.getenv(\"PLAYER_CHUNK_SIZE\", \"2000\"))\n",
        "PLAYER_CHUNK_OVERLAP = int(os.getenv(\"PLAYER_CHUNK_OVERLAP\", \"500\"))\n",
        "PLAYER_TOP_K = int(os.getenv(\"PLAYER_TOP_K\", \"15\"))\n",
        "PLAYER_STREAM_FILE_BYTES = int(os.getenv(\"PLAYER_STREAM_FILE_BYTES\", str(5 * 1024 * 1024)))\n",
        "\n",
        "\n",
        "def _normalize_text_player(text: str) -> str:\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
        "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def _iter_char_chunks_from_stream(stream, *, chunk_size: int, overlap: int) -> Iterator[str]:\n",
        "    buf = \"\"\n",
        "    step = max(1, chunk_size - overlap)\n",
        "    while True:\n",
        "        part = stream.read(64 * 1024)\n",
        "        if not part:\n",
        "            break\n",
        "        buf += part\n",
        "        while len(buf) >= chunk_size:\n",
        "            yield buf[:chunk_size]\n",
        "            buf = buf[step:]\n",
        "\n",
        "    tail = buf.strip()\n",
        "    if tail:\n",
        "        yield tail\n",
        "\n",
        "\n",
        "def _ocr_pdf_to_txt(pdf_path: Path, out_txt_path: Path) -> Tuple[bool, str]:\n",
        "    \"\"\"OCR PDF -> TXT. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (ok, message). –ü–∏—à–µ—Ç TXT —Ä—è–¥–æ–º —Å PDF.\"\"\"\n",
        "    try:\n",
        "        import pymupdf\n",
        "    except Exception as e:\n",
        "        return False, f\"pymupdf –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {e}\"\n",
        "\n",
        "    try:\n",
        "        import pytesseract\n",
        "        from PIL import Image\n",
        "    except Exception as e:\n",
        "        return False, f\"pytesseract/PIL –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã: {e}\"\n",
        "\n",
        "    try:\n",
        "        doc = pymupdf.open(str(pdf_path))\n",
        "    except Exception as e:\n",
        "        return False, f\"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å PDF: {e}\"\n",
        "\n",
        "    parts: List[str] = []\n",
        "    try:\n",
        "        for page_num in range(doc.page_count):\n",
        "            page = doc.load_page(page_num)\n",
        "            pix = page.get_pixmap(dpi=300)\n",
        "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
        "            text = pytesseract.image_to_string(img, lang=os.getenv(\"OCR_LANG\", \"rus+eng\"))\n",
        "            text = _normalize_text_player(text)\n",
        "            if text:\n",
        "                parts.append(text)\n",
        "            if page_num % 5 == 0:\n",
        "                gc.collect()\n",
        "    except Exception as e:\n",
        "        return False, f\"OCR –æ—à–∏–±–∫–∞: {e}\"\n",
        "    finally:\n",
        "        doc.close()\n",
        "\n",
        "    full = \"\\n\\n\".join(parts).strip()\n",
        "    if not full:\n",
        "        return False, \"OCR –Ω–µ –∏–∑–≤–ª—ë–∫ —Ç–µ–∫—Å—Ç (–ø—É—Å—Ç–æ)\"\n",
        "\n",
        "    try:\n",
        "        out_txt_path.write_text(full, encoding=\"utf-8\", errors=\"ignore\")\n",
        "    except Exception as e:\n",
        "        return False, f\"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å TXT: {e}\"\n",
        "\n",
        "    return True, f\"OK: {out_txt_path.name}\"\n",
        "\n",
        "\n",
        "class PlayerKnowledgeBase:\n",
        "    def __init__(self, dataset_dir: Path = PLAYER_DATASET_DIR, faiss_dir: Path = PLAYER_FAISS_DIR, embed_model: Optional[str] = None):\n",
        "        self.dataset_dir = Path(dataset_dir)\n",
        "        self.faiss_dir = Path(faiss_dir)\n",
        "        self.embed_model = embed_model or PLAYER_EMBED_MODEL\n",
        "        self._vectorstore = None\n",
        "        self._embeddings = None\n",
        "        self._splitter = None\n",
        "        self.last_status = \"init\"\n",
        "        self.faiss_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def _get_embeddings(self):\n",
        "        if self._embeddings is None:\n",
        "            from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "            device = \"cuda\" if os.getenv(\"USE_CUDA\", \"0\") == \"1\" else \"cpu\"\n",
        "            self._embeddings = HuggingFaceEmbeddings(\n",
        "                model_name=self.embed_model,\n",
        "                model_kwargs={\"device\": device},\n",
        "                encode_kwargs={\"normalize_embeddings\": True},\n",
        "            )\n",
        "            logger.info(\"Player embeddings initialized (%s) on %s\", self.embed_model, device)\n",
        "        return self._embeddings\n",
        "\n",
        "    def _reset_embeddings(self, embed_model: str):\n",
        "        self.embed_model = embed_model\n",
        "        self._embeddings = None\n",
        "\n",
        "    def _get_splitter(self):\n",
        "        if self._splitter is None:\n",
        "            from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "            self._splitter = RecursiveCharacterTextSplitter(\n",
        "                chunk_size=PLAYER_CHUNK_SIZE,\n",
        "                chunk_overlap=PLAYER_CHUNK_OVERLAP,\n",
        "                separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "            )\n",
        "        return self._splitter\n",
        "\n",
        "    def _load_vectorstore_if_exists(self):\n",
        "        if self._vectorstore is not None:\n",
        "            return self._vectorstore\n",
        "\n",
        "        index_file = self.faiss_dir / \"index.faiss\"\n",
        "        if not index_file.exists():\n",
        "            return None\n",
        "\n",
        "        from langchain_community.vectorstores import FAISS\n",
        "\n",
        "        try:\n",
        "            self._vectorstore = FAISS.load_local(\n",
        "                str(self.faiss_dir),\n",
        "                self._get_embeddings(),\n",
        "                allow_dangerous_deserialization=True,\n",
        "            )\n",
        "            logger.info(\"Player FAISS index loaded from %s\", self.faiss_dir)\n",
        "            return self._vectorstore\n",
        "        except Exception as e:\n",
        "            logger.exception(\"Player FAISS load failed with %s\", self.embed_model)\n",
        "\n",
        "        # Fallback: –µ—Å–ª–∏ –∏–Ω–¥–µ–∫—Å —Å–æ–±—Ä–∞–Ω –¥—Ä—É–≥–æ–π –º–æ–¥–µ–ª—å—é (–Ω–∞–ø—Ä–∏–º–µ—Ä mpnet), –ø—Ä–æ–±—É–µ–º –µ—é\n",
        "        try:\n",
        "            self._reset_embeddings(PLAYER_FALLBACK_EMBED_MODEL)\n",
        "            self._vectorstore = FAISS.load_local(\n",
        "                str(self.faiss_dir),\n",
        "                self._get_embeddings(),\n",
        "                allow_dangerous_deserialization=True,\n",
        "            )\n",
        "            logger.info(\"Player FAISS index loaded with fallback model (%s)\", self.embed_model)\n",
        "            return self._vectorstore\n",
        "        except Exception:\n",
        "            logger.exception(\"Player FAISS load failed even with fallback model\")\n",
        "            self._vectorstore = None\n",
        "            return None\n",
        "\n",
        "    def _save_vectorstore(self):\n",
        "        if self._vectorstore is not None:\n",
        "            self._vectorstore.save_local(str(self.faiss_dir))\n",
        "\n",
        "    def _iter_source_files(self) -> List[Path]:\n",
        "        if not self.dataset_dir.exists():\n",
        "            return []\n",
        "        files: List[Path] = []\n",
        "        for fp in sorted(self.dataset_dir.rglob(\"*\")):\n",
        "            if not fp.is_file():\n",
        "                continue\n",
        "            if fp.suffix.lower() in (\".txt\", \".md\", \".rst\", \".csv\", \".pdf\"):\n",
        "                files.append(fp)\n",
        "        return files\n",
        "\n",
        "    def ocr_pdfs_to_txt(self) -> str:\n",
        "        if not self.dataset_dir.exists():\n",
        "            return f\"Dataset –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.dataset_dir}\"\n",
        "\n",
        "        pdfs = [p for p in self._iter_source_files() if p.suffix.lower() == \".pdf\"]\n",
        "        if not pdfs:\n",
        "            return \"PDF –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –¥–ª—è OCR.\"\n",
        "\n",
        "        ok = 0\n",
        "        fail = 0\n",
        "        notes = []\n",
        "        for pdf in pdfs:\n",
        "            out_txt = pdf.with_suffix(\".txt\")\n",
        "            if out_txt.exists() and out_txt.stat().st_size > 200:\n",
        "                continue\n",
        "            done, msg = _ocr_pdf_to_txt(pdf, out_txt)\n",
        "            if done:\n",
        "                ok += 1\n",
        "            else:\n",
        "                fail += 1\n",
        "                notes.append(f\"{pdf.name}: {msg}\")\n",
        "\n",
        "        suffix = \"\" if not notes else (\"\\n\" + \"\\n\".join(notes[:10]))\n",
        "        return f\"OCR –≥–æ—Ç–æ–≤–æ. –£—Å–ø–µ—à–Ω–æ: {ok}, –æ—à–∏–±–æ–∫: {fail}.\" + suffix\n",
        "\n",
        "    def build_or_rebuild_index(self, *, force: bool = False) -> str:\n",
        "        from langchain_community.vectorstores import FAISS\n",
        "\n",
        "        self.last_status = \"build_start\"\n",
        "\n",
        "        if force:\n",
        "            self._vectorstore = None\n",
        "            for fp in self.faiss_dir.glob(\"*\"):\n",
        "                try:\n",
        "                    fp.unlink()\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "        self.ocr_pdfs_to_txt()\n",
        "\n",
        "        txts = [p for p in self._iter_source_files() if p.suffix.lower() in (\".txt\", \".md\", \".rst\", \".csv\")]\n",
        "        if not txts:\n",
        "            self.last_status = \"dataset_empty\"\n",
        "            return f\"–ù–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≤ {self.dataset_dir}\"\n",
        "\n",
        "        splitter = self._get_splitter()\n",
        "        docs_total = 0\n",
        "        files_used = 0\n",
        "        files_skipped = 0\n",
        "        vs = None\n",
        "\n",
        "        for i, fp in enumerate(txts):\n",
        "            try:\n",
        "                size = fp.stat().st_size\n",
        "            except Exception:\n",
        "                size = 0\n",
        "\n",
        "            try:\n",
        "                if size >= PLAYER_STREAM_FILE_BYTES:\n",
        "                    with fp.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "                        for chunk_id, chunk in enumerate(_iter_char_chunks_from_stream(f, chunk_size=PLAYER_CHUNK_SIZE, overlap=PLAYER_CHUNK_OVERLAP)):\n",
        "                            text = _normalize_text_player(chunk)\n",
        "                            if not text or len(text) < 50:\n",
        "                                continue\n",
        "                            docs = splitter.create_documents(\n",
        "                                [text],\n",
        "                                metadatas=[{\"source_file\": fp.name, \"rel_path\": str(fp.relative_to(self.dataset_dir)), \"chunk_id\": chunk_id}],\n",
        "                            )\n",
        "                            if not docs:\n",
        "                                continue\n",
        "                            if vs is None:\n",
        "                                vs = FAISS.from_documents(docs, self._get_embeddings())\n",
        "                            else:\n",
        "                                vs.add_documents(docs)\n",
        "                            docs_total += len(docs)\n",
        "                            if docs_total % 200 == 0:\n",
        "                                gc.collect()\n",
        "                    files_used += 1\n",
        "                else:\n",
        "                    raw = fp.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "                    text = _normalize_text_player(raw)\n",
        "                    if not text or len(text) < 50:\n",
        "                        files_skipped += 1\n",
        "                        continue\n",
        "                    docs = splitter.create_documents([text], metadatas=[{\"source_file\": fp.name, \"rel_path\": str(fp.relative_to(self.dataset_dir))}])\n",
        "                    if not docs:\n",
        "                        files_skipped += 1\n",
        "                        continue\n",
        "                    if vs is None:\n",
        "                        vs = FAISS.from_documents(docs, self._get_embeddings())\n",
        "                    else:\n",
        "                        vs.add_documents(docs)\n",
        "                    docs_total += len(docs)\n",
        "                    files_used += 1\n",
        "\n",
        "                if i % 5 == 0:\n",
        "                    gc.collect()\n",
        "\n",
        "            except Exception as e:\n",
        "                files_skipped += 1\n",
        "                logger.exception(\"Player index build: failed for %s\", fp)\n",
        "                self.last_status = f\"build_error:{fp.name}:{e}\"\n",
        "\n",
        "        if vs is None or docs_total == 0:\n",
        "            self.last_status = \"index_empty\"\n",
        "            return \"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏\"\n",
        "\n",
        "        self._vectorstore = vs\n",
        "        self._save_vectorstore()\n",
        "        self.last_status = \"ready\"\n",
        "        return f\"Player –∏–Ω–¥–µ–∫—Å –ø–æ—Å—Ç—Ä–æ–µ–Ω: {docs_total} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤. –§–∞–π–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {files_used}, –ø—Ä–æ–ø—É—â–µ–Ω–æ: {files_skipped}. –ü—É—Ç—å: {self.faiss_dir}\"\n",
        "\n",
        "    def search(self, query: str, *, top_k: int = PLAYER_TOP_K) -> Tuple[bool, str]:\n",
        "        self.last_status = \"search\"\n",
        "        vs = self._load_vectorstore_if_exists()\n",
        "        if vs is None:\n",
        "            self.last_status = \"index_missing\"\n",
        "            return False, \"\"\n",
        "\n",
        "        try:\n",
        "            ntotal = int(getattr(vs, \"index\").ntotal)\n",
        "        except Exception:\n",
        "            ntotal = None\n",
        "\n",
        "        if ntotal == 0:\n",
        "            self.last_status = \"index_empty\"\n",
        "            return False, \"\"\n",
        "\n",
        "        docs = vs.similarity_search(query, k=top_k)\n",
        "        if not docs:\n",
        "            self.last_status = \"no_docs\"\n",
        "            return False, \"\"\n",
        "\n",
        "        contexts = []\n",
        "        for d in docs:\n",
        "            meta = d.metadata or {}\n",
        "            src = meta.get(\"rel_path\") or meta.get(\"source_file\") or \"unknown\"\n",
        "            body = (d.page_content or \"\").strip()\n",
        "            if not body:\n",
        "                continue\n",
        "            contexts.append(f\"[{src}]\\n\" + body)\n",
        "\n",
        "        if not contexts:\n",
        "            self.last_status = \"no_text\"\n",
        "            return False, \"\"\n",
        "\n",
        "        self.last_status = \"found\"\n",
        "        return True, \"\\n\\n---\\n\\n\".join(contexts)\n",
        "\n",
        "\n",
        "player_kb = PlayerKnowledgeBase()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-14 20:17:10,467 INFO Bot started\n",
            "2026-01-14 20:17:10,867 INFO HTTP Request: POST https://api.telegram.org/bot8573638607:AAESEdAJowSF3XpRy-0OkfxaT8MmIElDI5U/getMe \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:10,942 INFO HTTP Request: POST https://api.telegram.org/bot8573638607:AAESEdAJowSF3XpRy-0OkfxaT8MmIElDI5U/deleteWebhook \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:10,945 INFO Application started\n",
            "2026-01-14 20:17:11,300 INFO HTTP Request: POST https://api.telegram.org/bot8573638607:AAESEdAJowSF3XpRy-0OkfxaT8MmIElDI5U/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:11,469 INFO HTTP Request: POST https://api.telegram.org/bot8573638607:AAESEdAJowSF3XpRy-0OkfxaT8MmIElDI5U/sendMessage \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:15,606 INFO HTTP Request: POST https://api.telegram.org/bot8573638607:AAESEdAJowSF3XpRy-0OkfxaT8MmIElDI5U/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:15,724 INFO HTTP Request: POST https://api.telegram.org/bot8573638607:AAESEdAJowSF3XpRy-0OkfxaT8MmIElDI5U/sendMessage \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:16,644 INFO HTTP Request: POST https://api.telegram.org/bot8573638607:AAESEdAJowSF3XpRy-0OkfxaT8MmIElDI5U/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:16,758 INFO HTTP Request: POST https://api.telegram.org/bot8573638607:AAESEdAJowSF3XpRy-0OkfxaT8MmIElDI5U/sendMessage \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:18,301 INFO HTTP Request: POST https://api.telegram.org/bot8573638607:AAESEdAJowSF3XpRy-0OkfxaT8MmIElDI5U/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:18,465 INFO HTTP Request: POST https://api.telegram.org/bot8573638607:AAESEdAJowSF3XpRy-0OkfxaT8MmIElDI5U/sendMessage \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:20,777 INFO HTTP Request: POST https://api.telegram.org/bot8573638607:AAESEdAJowSF3XpRy-0OkfxaT8MmIElDI5U/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:20,977 INFO HTTP Request: POST https://api.telegram.org/bot8573638607:AAESEdAJowSF3XpRy-0OkfxaT8MmIElDI5U/sendMessage \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:22,725 INFO HTTP Request: POST https://api.telegram.org/bot8573638607:AAESEdAJowSF3XpRy-0OkfxaT8MmIElDI5U/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:22,873 INFO HTTP Request: POST https://api.telegram.org/bot8573638607:AAESEdAJowSF3XpRy-0OkfxaT8MmIElDI5U/sendMessage \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:23,677 INFO HTTP Request: POST https://api.telegram.org/bot8573638607:AAESEdAJowSF3XpRy-0OkfxaT8MmIElDI5U/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:23,903 INFO HTTP Request: POST https://api.telegram.org/bot8573638607:AAESEdAJowSF3XpRy-0OkfxaT8MmIElDI5U/sendMessage \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:28,222 INFO HTTP Request: POST https://api.telegram.org/bot8573638607:AAESEdAJowSF3XpRy-0OkfxaT8MmIElDI5U/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:28,345 INFO HTTP Request: POST https://api.telegram.org/bot8573638607:AAESEdAJowSF3XpRy-0OkfxaT8MmIElDI5U/sendMessage \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:29,747 INFO HTTP Request: POST https://api.telegram.org/bot8573638607:AAESEdAJowSF3XpRy-0OkfxaT8MmIElDI5U/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2026-01-14 20:17:29,905 INFO HTTP Request: POST https://api.telegram.org/bot8573638607:AAESEdAJowSF3XpRy-0OkfxaT8MmIElDI5U/sendMessage \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "# FAISS Telegram bot (compact). Run this cell.\n",
        "import os, re, time, json, asyncio, logging\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from telegram import ReplyKeyboardMarkup, KeyboardButton, Update\n",
        "from telegram.ext import ApplicationBuilder, ContextTypes, MessageHandler, CommandHandler, filters\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\n",
        "logger = logging.getLogger(\"rag-dnd-bot\")\n",
        "\n",
        "# ----------------- Config -----------------\n",
        "TG_BOT_TOKEN = os.getenv(\"TG_BOT_TOKEN\")\n",
        "OLLAMA_API_URL = os.getenv(\"OLLAMA_API_URL\", \"https://ollama.com/api/chat\")\n",
        "OLLAMA_API_KEY = os.getenv(\"OLLAMA_API_KEY\")\n",
        "OLLAMA_MODEL = os.getenv(\"OLLAMA_MODEL\", \"gpt-oss:20b-cloud\")\n",
        "\n",
        "OLLAMA_TEMPERATURE = float(os.getenv(\"OLLAMA_TEMPERATURE\", \"0.6\"))\n",
        "OLLAMA_TEMPERATURE_REPLIES = float(os.getenv(\"OLLAMA_TEMPERATURE_REPLIES\", \"0.2\"))\n",
        "\n",
        "OLLAMA_NUM_PREDICT = int(os.getenv(\"OLLAMA_NUM_PREDICT\", \"900\"))\n",
        "OLLAMA_NUM_PREDICT_REPLIES = int(os.getenv(\"OLLAMA_NUM_PREDICT_REPLIES\", \"450\"))\n",
        "\n",
        "TELEGRAM_MAX_CHARS = int(os.getenv(\"TELEGRAM_MAX_CHARS\", \"3800\"))\n",
        "\n",
        "FAISS_DIR = Path(os.getenv(\"FAISS_DIR\", \"artifacts/faiss_campaign_knowledge\"))\n",
        "\n",
        "VOICE_MALE = \"male\"\n",
        "VOICE_FEMALE = \"female\"\n",
        "\n",
        "# ----------------- Keyboards -----------------\n",
        "KB_MAIN = ReplyKeyboardMarkup(\n",
        "    [[KeyboardButton(\"Dungeon Master üßô‚Äç‚ôÇÔ∏è\"), KeyboardButton(\"Player üé≤\"), KeyboardButton(\"Restart üîÑ\")]],\n",
        "    resize_keyboard=True,\n",
        ")\n",
        "KB_PLAYER = ReplyKeyboardMarkup(\n",
        "    [[KeyboardButton(\"–í–æ–ø—Ä–æ—Å—ã –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º\"), KeyboardButton(\"–ü–æ–º–æ—â—å –≤ —Å–∏—Ç—É–∞—Ü–∏–∏\")], [KeyboardButton(\"‚Üê –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é\")]],\n",
        "    resize_keyboard=True,\n",
        ")\n",
        "KB_DM = ReplyKeyboardMarkup(\n",
        "    [\n",
        "        [KeyboardButton(\"–•—Ä–∞–Ω–∏–ª–∏—â–µ –∑–Ω–∞–Ω–∏–π\"), KeyboardButton(\"–°–æ–∑–¥–∞–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞\")],\n",
        "        [KeyboardButton(\"–†–µ–ø–ª–∏–∫–∏\"), KeyboardButton(\"–ë–æ–µ–≤–∫–∞\")],\n",
        "        [KeyboardButton(\"–ó–∞–≥—Ä—É–∑–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é\")],\n",
        "        [KeyboardButton(\"‚Üê –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é\")],\n",
        "    ],\n",
        "    resize_keyboard=True,\n",
        ")\n",
        "KB_REPLIES = ReplyKeyboardMarkup(\n",
        "    [[KeyboardButton(\"–¢–µ–∫—Å—Ç\"), KeyboardButton(\"–û–∑–≤—É—á–∫–∞ + —Ç–µ–∫—Å—Ç\")], [KeyboardButton(\"‚Üê –ù–∞–∑–∞–¥ (DM)\")]],\n",
        "    resize_keyboard=True,\n",
        ")\n",
        "KB_VOICE = ReplyKeyboardMarkup(\n",
        "    [[KeyboardButton(\"–ú—É–∂—Å–∫–æ–π\"), KeyboardButton(\"–ñ–µ–Ω—Å–∫–∏–π\")], [KeyboardButton(\"‚Üê –ù–∞–∑–∞–¥ (DM)\")]],\n",
        "    resize_keyboard=True,\n",
        ")\n",
        "\n",
        "WELCOME_TEXT = \"üé≤ RAG DnD Assistant\\n–í—ã–±–µ—Ä–∏ —Ä–æ–ª—å.\"\n",
        "\n",
        "# ----------------- Helpers -----------------\n",
        "def normalize_text(text: str) -> str:\n",
        "    text = (text or \"\").replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
        "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def chunk_for_tg(text: str, max_chars: int = TELEGRAM_MAX_CHARS):\n",
        "    t = (text or \"\").strip()\n",
        "    if not t:\n",
        "        return [\"\"]\n",
        "    out = []\n",
        "    while t:\n",
        "        if len(t) <= max_chars:\n",
        "            out.append(t)\n",
        "            break\n",
        "        cut = t.rfind(\"\\n\\n\", 0, max_chars)\n",
        "        if cut < max_chars * 0.4:\n",
        "            cut = t.rfind(\"\\n\", 0, max_chars)\n",
        "        if cut < max_chars * 0.4:\n",
        "            cut = t.rfind(\" \", 0, max_chars)\n",
        "        if cut < max_chars * 0.4:\n",
        "            cut = max_chars\n",
        "        out.append(t[:cut].rstrip())\n",
        "        t = t[cut:].lstrip()\n",
        "    return out\n",
        "\n",
        "\n",
        "async def safe_reply(update: Update, text: str, *, reply_markup=None):\n",
        "    for i, part in enumerate(chunk_for_tg(text)):\n",
        "        if i == 0:\n",
        "            await update.message.reply_text(part, reply_markup=reply_markup)\n",
        "        else:\n",
        "            await update.message.reply_text(part)\n",
        "\n",
        "\n",
        "def _looks_like_bad_reply(text: str) -> bool:\n",
        "    t = normalize_text(text)\n",
        "    if not t:\n",
        "        return True\n",
        "    if len(t) > 700:\n",
        "        return True\n",
        "    low = t.lower()\n",
        "    bad_words = [\"–∑–∞—à–∫–≤–∞—Ä\", \"–∫—Ä–∏–Ω–∂\", \"—Ä–æ—Ñ–ª\", \"–ª–æ–ª\", \"–º–µ–º\", \"–∏–Ω—Ç–µ—Ä–Ω–µ—Ç\", \"—Å–º–∞—Ä—Ç—Ñ–æ–Ω\", \"–∫–æ–º–ø—å—é—Ç–µ—Ä\", \"–ª–∞–∑–µ—Ä\", \"—Ä–∞–∫–µ—Ç–∞\", \"—ç–ª–µ–∫—Ç—Ä–∏—á\"]\n",
        "    return any(w in low for w in bad_words)\n",
        "\n",
        "\n",
        "def _player_warning(found: bool) -> str:\n",
        "    if found:\n",
        "        return \"\"\n",
        "    return \"–Ø –Ω–µ –Ω–∞—à—ë–ª –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –∏–≥—Ä–æ–∫–∞; –æ—Ç–≤–µ—Ç –Ω–∏–∂–µ ‚Äî –ø–æ –æ–±—â–∏–º –∑–Ω–∞–Ω–∏—è–º D&D 5e.\"\n",
        "\n",
        "\n",
        "# ----------------- Ollama -----------------\n",
        "class OllamaCloud:\n",
        "    def __init__(self):\n",
        "        self.url = OLLAMA_API_URL\n",
        "        self.model = OLLAMA_MODEL\n",
        "        self.key = OLLAMA_API_KEY\n",
        "\n",
        "    def chat(self, messages, *, num_predict: int, temperature: float, timeout: int = 120) -> str:\n",
        "        import requests\n",
        "\n",
        "        headers = {\"Content-Type\": \"application/json\"}\n",
        "        if self.key:\n",
        "            headers[\"Authorization\"] = \"Bearer \" + self.key\n",
        "\n",
        "        body = {\n",
        "            \"model\": self.model,\n",
        "            \"messages\": messages,\n",
        "            \"stream\": False,\n",
        "            \"options\": {\"num_predict\": int(num_predict), \"temperature\": float(temperature)},\n",
        "        }\n",
        "        r = requests.post(self.url, json=body, headers=headers, timeout=timeout)\n",
        "        r.raise_for_status()\n",
        "        data = r.json() if r.content else {}\n",
        "        msg = (data.get(\"message\") or {})\n",
        "        content = msg.get(\"content\")\n",
        "        if isinstance(content, str) and content.strip():\n",
        "            return content.strip()\n",
        "        resp = data.get(\"response\")\n",
        "        if isinstance(resp, str) and resp.strip():\n",
        "            return resp.strip()\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def ollama_with_retries(ollama: OllamaCloud, messages, *, num_predict: int, temperature: float, retries: int = 2) -> str:\n",
        "    for i in range(retries + 1):\n",
        "        try:\n",
        "            out = (ollama.chat(messages, num_predict=num_predict, temperature=temperature) or \"\").strip()\n",
        "            if out:\n",
        "                return out\n",
        "        except Exception:\n",
        "            pass\n",
        "        time.sleep(0.6 * (i + 1))\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "ollama = OllamaCloud()\n",
        "\n",
        "# ----------------- DM campaign retrieval -----------------\n",
        "class CampaignKB:\n",
        "    def __init__(self, faiss_dir: Path):\n",
        "        self.faiss_dir = Path(faiss_dir)\n",
        "        self._vs = None\n",
        "        self._emb = None\n",
        "\n",
        "    def _embeddings(self):\n",
        "        if self._emb is None:\n",
        "            from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "            device = \"cuda\" if os.getenv(\"USE_CUDA\", \"0\") == \"1\" else \"cpu\"\n",
        "            self._emb = HuggingFaceEmbeddings(\n",
        "                model_name=os.getenv(\"SAFE_EMBED_MODEL\", \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"),\n",
        "                model_kwargs={\"device\": device},\n",
        "                encode_kwargs={\"normalize_embeddings\": True},\n",
        "            )\n",
        "        return self._emb\n",
        "\n",
        "    def _load(self):\n",
        "        if self._vs is not None:\n",
        "            return self._vs\n",
        "        if not (self.faiss_dir / \"index.faiss\").exists():\n",
        "            return None\n",
        "        from langchain_community.vectorstores import FAISS\n",
        "        self._vs = FAISS.load_local(str(self.faiss_dir), self._embeddings(), allow_dangerous_deserialization=True)\n",
        "        return self._vs\n",
        "\n",
        "    def retrieve(self, query: str, k: int = 6) -> str:\n",
        "        vs = self._load()\n",
        "        if vs is None:\n",
        "            return \"\"\n",
        "        docs = vs.similarity_search(query, k=k)\n",
        "        parts = []\n",
        "        for d in docs:\n",
        "            meta = d.metadata or {}\n",
        "            src = meta.get(\"source_file\") or \"unknown\"\n",
        "            page = meta.get(\"page\")\n",
        "            pfx = f\"[{src}{', —Å—Ç—Ä. ' + str(page) if page else ''}]\\n\"\n",
        "            txt = (d.page_content or \"\").strip()\n",
        "            if txt:\n",
        "                parts.append(pfx + txt)\n",
        "        return \"\\n\\n---\\n\\n\".join(parts).strip()\n",
        "\n",
        "\n",
        "campaign_kb = CampaignKB(FAISS_DIR)\n",
        "\n",
        "# ----------------- Player KB -----------------\n",
        "# player_kb is created in previous cell (PlayerKnowledgeBase)\n",
        "\n",
        "def player_retrieve(query: str, k: int = 15) -> tuple[bool, str]:\n",
        "    try:\n",
        "        return player_kb.search(query, top_k=k)  # type: ignore\n",
        "    except Exception:\n",
        "        return False, \"\"\n",
        "\n",
        "\n",
        "def player_answer(prompt_template: str, user_text: str) -> str:\n",
        "    found, ctx = player_retrieve(user_text, k=15)\n",
        "    warn = _player_warning(found)\n",
        "\n",
        "    prompt = prompt_template + \"\\n\\n–§—Ä–∞–≥–º–µ–Ω—Ç—ã –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏–≥—Ä–æ–∫–∞:\\n\" + (ctx if ctx else \"(–Ω–µ—Ç)\") + \"\\n\\n–ó–∞–ø—Ä–æ—Å –∏–≥—Ä–æ–∫–∞:\\n\" + (user_text or \"\")\n",
        "\n",
        "    msgs = [\n",
        "        {\"role\": \"system\", \"content\": \"–í—ã–≤–æ–¥ —Ç–æ–ª—å–∫–æ –ø—Ä–æ—Å—Ç—ã–º —Ç–µ–∫—Å—Ç–æ–º. –ë–µ–∑ Markdown/JSON/—Ç–∞–±–ª–∏—Ü.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "    ]\n",
        "\n",
        "    out = ollama_with_retries(ollama, msgs, num_predict=OLLAMA_NUM_PREDICT, temperature=OLLAMA_TEMPERATURE, retries=2)\n",
        "    out = normalize_text(out)\n",
        "    if not out:\n",
        "        return \"–°–µ—Ä–≤–∏—Å –æ—Ç–≤–µ—Ç–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ –≤–µ—Ä–Ω—É–ª —Ç–µ–∫—Å—Ç. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.\"\n",
        "\n",
        "    return (warn + \"\\n\\n\" + out).strip() if warn else out\n",
        "\n",
        "\n",
        "# ----------------- TTS (Silero) -----------------\n",
        "class SileroTTS:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.sample_rate = 48000\n",
        "        self.speakers = {\"–ú—É–∂—Å–∫–æ–π\": \"aidar\", \"–ñ–µ–Ω—Å–∫–∏–π\": \"xenia\", VOICE_MALE: \"aidar\", VOICE_FEMALE: \"xenia\"}\n",
        "\n",
        "    def _init(self):\n",
        "        if self.model is not None:\n",
        "            return\n",
        "        import torch\n",
        "        self.model, _ = torch.hub.load(repo_or_dir=\"snakers4/silero-models\", model=\"silero_tts\", language=\"ru\", speaker=\"v5_ru\")\n",
        "        self.model.to(torch.device(\"cpu\"))\n",
        "\n",
        "    def synthesize(self, text: str, voice: str, out_dir: Path) -> Path:\n",
        "        import numpy as np\n",
        "        self._init()\n",
        "        speaker = self.speakers.get(voice, \"aidar\")\n",
        "        out_dir.mkdir(parents=True, exist_ok=True)\n",
        "        base = f\"tts_{speaker}_{int(time.time()*1000)}\"\n",
        "        wav = out_dir / f\"{base}.wav\"\n",
        "        audio = self.model.apply_tts(text=(text or \"\").strip(), speaker=speaker, sample_rate=self.sample_rate, put_accent=True, put_yo=True)\n",
        "        audio = np.asarray(audio)\n",
        "        try:\n",
        "            import soundfile as sf\n",
        "            sf.write(str(wav), audio, self.sample_rate)\n",
        "        except Exception:\n",
        "            from scipy.io.wavfile import write as w\n",
        "            max_abs = float(np.max(np.abs(audio))) or 1.0\n",
        "            w(str(wav), self.sample_rate, (audio / max_abs * 32767).astype(np.int16))\n",
        "        try:\n",
        "            from pydub import AudioSegment\n",
        "            mp3 = out_dir / f\"{base}.mp3\"\n",
        "            AudioSegment.from_wav(str(wav)).export(str(mp3), format=\"mp3\")\n",
        "            return mp3\n",
        "        except Exception:\n",
        "            return wav\n",
        "\n",
        "\n",
        "tts = SileroTTS()\n",
        "\n",
        "# ----------------- NPC replies -----------------\n",
        "NPC_DIALOG_SYSTEM = NPC_DIALOG_PROMPT\n",
        "\n",
        "\n",
        "def gen_npc_reply(user_prompt: str) -> str:\n",
        "    ctx = campaign_kb.retrieve(user_prompt, k=6)\n",
        "    payload = \"–ö–æ–Ω—Ç–µ–∫—Å—Ç –∫–∞–º–ø–∞–Ω–∏–∏:\\n\" + (ctx if ctx else \"(–Ω–µ—Ç)\") + \"\\n\\n–°–∏—Ç—É–∞—Ü–∏—è/—Ä–µ–ø–ª–∏–∫–∞ –∏–≥—Ä–æ–∫–∞:\\n\" + (user_prompt or \"\")\n",
        "    msgs = [{\"role\": \"system\", \"content\": NPC_DIALOG_SYSTEM}, {\"role\": \"user\", \"content\": payload}]\n",
        "    out = ollama_with_retries(ollama, msgs, num_predict=OLLAMA_NUM_PREDICT_REPLIES, temperature=OLLAMA_TEMPERATURE_REPLIES, retries=2)\n",
        "    out = normalize_text(out)\n",
        "    if not out or _looks_like_bad_reply(out):\n",
        "        msgs2 = [\n",
        "            {\"role\": \"system\", \"content\": \"–ü–µ—Ä–µ–ø–∏—à–∏ –∫–∞–∫ –æ–¥–Ω—É —Å–≤—è–∑–Ω—É—é —Ä–µ–ø–ª–∏–∫—É NPC (1‚Äì3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è), —Ö–æ—Ä–æ—à–∏–π —Ä—É—Å—Å–∫–∏–π, –±–µ–∑ —Å–ª–µ–Ω–≥–∞ –∏ –±–µ–∑ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤.\"},\n",
        "            {\"role\": \"user\", \"content\": payload + \"\\n\\n–ß–µ—Ä–Ω–æ–≤–∏–∫:\\n\" + (out or \"\")},\n",
        "        ]\n",
        "        out2 = normalize_text(ollama_with_retries(ollama, msgs2, num_predict=OLLAMA_NUM_PREDICT_REPLIES, temperature=0.1, retries=2))\n",
        "        if out2:\n",
        "            out = out2\n",
        "    return out or \"–°–µ—Ä–≤–∏—Å –æ—Ç–≤–µ—Ç–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ –≤–µ—Ä–Ω—É–ª —Ç–µ–∫—Å—Ç. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.\"\n",
        "\n",
        "\n",
        "# ----------------- Bot handlers -----------------\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    context.user_data.clear()\n",
        "    await safe_reply(update, WELCOME_TEXT, reply_markup=KB_MAIN)\n",
        "\n",
        "\n",
        "async def router(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    text = (update.message.text or \"\").strip()\n",
        "\n",
        "    # Global navigation\n",
        "    if text == \"Restart üîÑ\":\n",
        "        context.user_data.clear()\n",
        "        await safe_reply(update, \"–ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω.\", reply_markup=KB_MAIN)\n",
        "        return\n",
        "    if text == \"‚Üê –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é\":\n",
        "        context.user_data.clear()\n",
        "        await safe_reply(update, WELCOME_TEXT, reply_markup=KB_MAIN)\n",
        "        return\n",
        "\n",
        "    # Role selection (repeatable)\n",
        "    if text == \"Dungeon Master üßô‚Äç‚ôÇÔ∏è\":\n",
        "        context.user_data[\"role\"] = \"dm\"\n",
        "        context.user_data[\"mode\"] = None\n",
        "        await safe_reply(update, \"–ú–µ–Ω—é –º–∞—Å—Ç–µ—Ä–∞:\", reply_markup=KB_DM)\n",
        "        return\n",
        "    if text == \"Player üé≤\":\n",
        "        context.user_data[\"role\"] = \"player\"\n",
        "        context.user_data[\"mode\"] = None\n",
        "        await safe_reply(update, \"–ú–µ–Ω—é –∏–≥—Ä–æ–∫–∞:\", reply_markup=KB_PLAYER)\n",
        "        return\n",
        "\n",
        "    role = context.user_data.get(\"role\")\n",
        "    mode = context.user_data.get(\"mode\")\n",
        "\n",
        "    # Player menus\n",
        "    if role == \"player\":\n",
        "        if text == \"–í–æ–ø—Ä–æ—Å—ã –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º\":\n",
        "            context.user_data[\"mode\"] = \"player_rules\"\n",
        "            await safe_reply(update, \"–ó–∞–¥–∞–π –≤–æ–ø—Ä–æ—Å –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º:\")\n",
        "            return\n",
        "        if text == \"–ü–æ–º–æ—â—å –≤ —Å–∏—Ç—É–∞—Ü–∏–∏\":\n",
        "            context.user_data[\"mode\"] = \"player_situation\"\n",
        "            await safe_reply(update, \"–û–ø–∏—à–∏ —Å–∏—Ç—É–∞—Ü–∏—é:\")\n",
        "            return\n",
        "\n",
        "        if mode == \"player_rules\":\n",
        "            await safe_reply(update, player_answer(PLAYER_RULES_PROMPT, text))\n",
        "            return\n",
        "        if mode == \"player_situation\":\n",
        "            await safe_reply(update, player_answer(PLAYER_SITUATION_PROMPT, text))\n",
        "            return\n",
        "\n",
        "        await safe_reply(update, \"–ú–µ–Ω—é –∏–≥—Ä–æ–∫–∞:\", reply_markup=KB_PLAYER)\n",
        "        return\n",
        "\n",
        "    # DM menus\n",
        "    if role == \"dm\":\n",
        "        if text == \"–†–µ–ø–ª–∏–∫–∏\":\n",
        "            context.user_data[\"mode\"] = \"replies_menu\"\n",
        "            await safe_reply(update, \"–§–æ—Ä–º–∞—Ç:\", reply_markup=KB_REPLIES)\n",
        "            return\n",
        "        if text == \"–¢–µ–∫—Å—Ç\":\n",
        "            context.user_data[\"mode\"] = \"npc_text\"\n",
        "            await safe_reply(update, \"–ü—Ä–æ–º–ø—Ç –¥–ª—è —Ä–µ–ø–ª–∏–∫–∏:\")\n",
        "            return\n",
        "        if text == \"–û–∑–≤—É—á–∫–∞ + —Ç–µ–∫—Å—Ç\":\n",
        "            context.user_data[\"mode\"] = \"npc_tts_voice\"\n",
        "            await safe_reply(update, \"–í—ã–±–µ—Ä–∏ –≥–æ–ª–æ—Å NPC:\", reply_markup=KB_VOICE)\n",
        "            return\n",
        "        if text == \"–ú—É–∂—Å–∫–æ–π\" and mode == \"npc_tts_voice\":\n",
        "            context.user_data[\"tts_voice\"] = VOICE_MALE\n",
        "            context.user_data[\"mode\"] = \"npc_tts\"\n",
        "            await safe_reply(update, \"–û—Ç–ø—Ä–∞–≤—å –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ä–µ–ø–ª–∏–∫–∏ NPC (–≤–µ—Ä–Ω—É —Ç–µ–∫—Å—Ç + –∞—É–¥–∏–æ).\", reply_markup=KB_REPLIES)\n",
        "            return\n",
        "        if text == \"–ñ–µ–Ω—Å–∫–∏–π\" and mode == \"npc_tts_voice\":\n",
        "            context.user_data[\"tts_voice\"] = VOICE_FEMALE\n",
        "            context.user_data[\"mode\"] = \"npc_tts\"\n",
        "            await safe_reply(update, \"–û—Ç–ø—Ä–∞–≤—å –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ä–µ–ø–ª–∏–∫–∏ NPC (–≤–µ—Ä–Ω—É —Ç–µ–∫—Å—Ç + –∞—É–¥–∏–æ).\", reply_markup=KB_REPLIES)\n",
        "            return\n",
        "\n",
        "        mode = context.user_data.get(\"mode\")\n",
        "\n",
        "        if mode == \"npc_text\":\n",
        "            await safe_reply(update, gen_npc_reply(text))\n",
        "            return\n",
        "\n",
        "        if mode == \"npc_tts\":\n",
        "            reply = gen_npc_reply(text)\n",
        "            await safe_reply(update, reply)\n",
        "\n",
        "            voice = context.user_data.get(\"tts_voice\", VOICE_MALE)\n",
        "            out_dir = Path(\"artifacts/tts\")\n",
        "            loop = asyncio.get_running_loop()\n",
        "            try:\n",
        "                audio_path = await loop.run_in_executor(None, lambda: tts.synthesize(reply, voice, out_dir))\n",
        "                with open(audio_path, \"rb\") as f:\n",
        "                    await update.message.reply_audio(audio=f, filename=audio_path.name)\n",
        "            except Exception as e:\n",
        "                logger.exception(\"TTS error\")\n",
        "                await safe_reply(update, f\"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–∑–≤—É—á–∏—Ç—å: {e}\")\n",
        "            return\n",
        "\n",
        "        if text == \"‚Üê –ù–∞–∑–∞–¥ (DM)\":\n",
        "            context.user_data[\"mode\"] = None\n",
        "            await safe_reply(update, \"–ú–µ–Ω—é DM:\", reply_markup=KB_DM)\n",
        "            return\n",
        "\n",
        "        if text == \"–•—Ä–∞–Ω–∏–ª–∏—â–µ –∑–Ω–∞–Ω–∏–π\":\n",
        "            context.user_data[\"mode\"] = \"dm_knowledge\"\n",
        "            await safe_reply(update, \"–ó–∞–ø—Ä–æ—Å –ø–æ –∫–∞–º–ø–∞–Ω–∏–∏:\")\n",
        "            return\n",
        "\n",
        "        if mode == \"dm_knowledge\":\n",
        "            ctx = campaign_kb.retrieve(text, k=6)\n",
        "            if not ctx:\n",
        "                await safe_reply(update, \"–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ.\")\n",
        "                return\n",
        "            msgs = [\n",
        "                {\"role\": \"system\", \"content\": \"–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –ø–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º—É –∫–æ–Ω—Ç–µ–∫—Å—Ç—É. –ü—Ä–æ—Å—Ç—ã–º —Ç–µ–∫—Å—Ç–æ–º.\"},\n",
        "                {\"role\": \"user\", \"content\": ctx + \"\\n\\n–í–æ–ø—Ä–æ—Å: \" + text},\n",
        "            ]\n",
        "            out = normalize_text(ollama_with_retries(ollama, msgs, num_predict=OLLAMA_NUM_PREDICT, temperature=OLLAMA_TEMPERATURE, retries=2))\n",
        "            await safe_reply(update, out or \"–°–µ—Ä–≤–∏—Å –æ—Ç–≤–µ—Ç–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ –≤–µ—Ä–Ω—É–ª —Ç–µ–∫—Å—Ç. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.\")\n",
        "            return\n",
        "\n",
        "        await safe_reply(update, \"–ú–µ–Ω—é DM:\", reply_markup=KB_DM)\n",
        "        return\n",
        "\n",
        "    # No role chosen yet\n",
        "    await safe_reply(update, \"–í—ã–±–µ—Ä–∏ —Ä–æ–ª—å:\", reply_markup=KB_MAIN)\n",
        "\n",
        "\n",
        "def main():\n",
        "    if not TG_BOT_TOKEN:\n",
        "        raise RuntimeError(\"TG_BOT_TOKEN –Ω–µ –∑–∞–¥–∞–Ω\")\n",
        "\n",
        "    app = ApplicationBuilder().token(TG_BOT_TOKEN).build()\n",
        "    app.add_handler(CommandHandler(\"start\", start))\n",
        "    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, router))\n",
        "\n",
        "    logger.info(\"Bot started\")\n",
        "    app.run_polling(close_loop=False)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
